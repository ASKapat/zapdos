Here are my three threads I'm working concurrently on in the hope that one/some/all of them lead me to my goal of interfacing two physics domains (or as Yaqi I think aptly calls them InteriorNodalBC and InteriorIntegratedBC):

https://groups.google.com/forum/#!topic/moose-users/011fudvdHng (MeshModifiers)
https://groups.google.com/forum/#!topic/moose-users/u3qZrEXQvSg (Boundary ID in DGKernel)
https://groups.google.com/forum/#!topic/moose-users/iALxx76WhnU (Multiple-block, multiple-variable interface test)

More moose-user threads of interest:

Trying to get slope limiting into DG: https://groups.google.com/forum/#!search/yaqi$20convection/moose-users/EYaTNUsSkss/VZzZ-wZEdoQJ
Solving scalar pure advection problem, including DG and FV: https://groups.google.com/forum/#!searchin/moose-users/DG$20finite$20volume/moose-users/p6h7PqZNOrA/TZfG_cfUAwAJ


Universal File Datasets Summaries:
http://www.sdrl.uc.edu/sdrl/referenceinfo/universalfileformats/file-format-storehouse/universal-file-datasets-summary
https://docs.plm.automation.siemens.com/tdoc/nx/10/nx_help/#uid:index_advanced:xid602249:id625716:id625821

Roundtrip, flying in on Saturday: 354.70
Roundtrip, flying in on Friday: 354.70

Really good articles on the moose-user list:

preconditioners (authored by Mariana Rodriguez)

Joule heating is working. It simply appears that currently the energy losses due to ionzation and elastic collisions outweigh the energy gains due to Joule heating.

Going to really start investigating what prevents taking long time steps. With no off diag jacobian elements for electrons and ions and off diag element for potential turned off, and with the following variable scalings:

em: 1e-11
Arp: 1e-6
potential: 1e4

the step size at 1e-7 seconds is 1.6e-9

em: 1e-6
Arp: 1e-6
potential: 1e4

the step size at 1e-7 seconds is 1.6e-9

Currently not able to even get to 1e-7 seconds with NEWTON. Perhaps my Jacobian is wrong. But it could also be right.

Best sim fail: somewhere in the microsecond range. Specs for this best simulation: nx = 4000, nl_rel_tol = 1e-2, hypre boomeramg, no scaling of any variables. Looks like fail time was: 3.0207e-6 seconds. I think a kink between .01 and .015 meters is what dooms the simulation. It's good to know that I can repeat this: after removing the stabilization which I implemented later in these notes, I reproduced this same later fail time, which is still the gold standard (assuming that that is a legitimate measure). 

These simulation failures are fundamentally different from the problems I was having before. Before the solutions were all smooth and pretty but the solves were either diverging or just going too slowly. I believe that this was simply because my relative tolerance was too high. If making the tolerance higher doesn't introduce oscillations in the solution and it allows the time steps to be much longer, than I am absolutely going to increase the tolerance! My priority is getting a solution. I don't care if there's too much diffusion for example. I don't give a damn about that. 

However, now I'm seeing oscillations. Fundamentally different problem. A better problem in my opinion. 

Three individual things I'm going to try (only change one variable at a time! Be patient!!!)

Test suite #1

1) Scale up the potential residual. Fail time: 5.50e-7 seconds
   Worse!
2) Increase the mesh density (Increased from 4000 to 8000 elements). Petsc failed with message: "Computed Nan differencing parameter h." Fail tiem again at 1.27e-8 seconds. So all the dependent variable solutions look beautifully smooth. However, there is an oscillation in the electron temperature at the cathode. This could be relevant because the electron temperature is in the source term for the electrons and ions. There are two things that should be done here. 1) I am going to try doubling the mesh resolution again to see if I can completely remove the oscillations. 2) It's worth looking into whether there are suggestions in combating the "Nan differencing parameter" for Petsc. Perhaps the recent messages on the Moose message board about Petsc error on fine mesh? 
a) From the fine mesh thread, which didn't make any reference to my particular error, a guy went from using ds for -mat_mffd_type to wp and his problem worked. -mat_mffd_type is for matrix free formulations (thus the mf). There is another petsc option, -mat_fd_type, which I believe is used if you're actually forming the Jacobian matrix (perhaps Newton?). 
b) In one thread from MOOSE mentioned the "Nan differencing parameter", John Mangeri said he was getting this error when using hypre and boomeramg. He said that when he went away from that preconditioner, he no longer experienced that problem. In a separate thread, Derek suggested that this generally means that a Nan is occurring somewhere in the residual, e.g. a divide by zero or sqrt of negative number. I personally have a hard time believing this though, especially considering my logarithmic formulation.

3) Decrease the relative tolerance. (Decreased from 1e-2 to 1e-3). Petsc failed with message: "Computed Nan differencing parameter h." Fail time: 1.27e-8 seconds. I didn't check how the solutions looked when the problem failed. If there were no oscillations in the solution, then the problem wasn't with the solution.
Way worse!

Test suite #2

1) Increased from 8000 to 16000 elements to see whether I can completely eliminate oscillations or see the "Nan differencing" error again. Fail time = 2.7911e-6. Reason for fail: looks like oscillations. It's always hard to know where the oscillations originate from. Is it oscillations in the bulk? Is it the oscillations at the boundary? Is it the electron temperature? Is it the electron density? Is it the argon density? The residuals of em, Arp, and mean_en are all about the same value. em is the highest. 

Oscillations are my problem. Paths to solution:

1) Stabilization -> Artificial diffusion
   Back to 4000 elements. With the stabilization, fail at 2.59839e-6 seconds. It looks like a kink forms around 5.5e-7 seconds. There aren't nearly as many oscillations in this simulation as in the 16000 element simulation. 
2) Mesh refinement -> Salome tutorial

Table of fail times for energy formulation:
4000 elements. nl_rel_tol = 1e-2. No stabilization. Fail time = 3.0207e-6 (normal fail)
4000 elements. nl_rel_tol = 1e-2. With stabilization. Fail time = 2.59839e-6 (normal fail)
4000 elements. nl_rel_tol = 1e-3. With stabilization. Fail time = 9.9839e-07 (normal fail)
16000 elements. nl_rel_tol = 1e-2. No stabilization. Fail time = 2.7911e-6 (normal fail)
8000 elements. nl_rel_tol = 1e-2. No stabilization. Fail time = 1.27e-8 (Nan differencing parameter)
4000 elements. nl_rel_tol = 1e-3. No stabilization. Fail time = 1.27e-8 (Nan differencing parameter)
8000 elements. nl_rel_tol = 1e-4. With stabilization. Fail time = 9.278e-08 (normal fail)
4000 elements. nl_rel_tol = 1e-2. No stabilization. Townsend form. Fail time = 6.493e-8 seconds. At least there no kinks this time. The problems were all in the oscillations at the cathode. 
4000 elements. nl_rel_tol = 1e-2. With stabilization. Townsend form. Fail time = 2.7639e-7 seconds. At least there no kinks this time. The problems were all in the oscillations at the cathode. And yes there are a lot of oscillations. Hahahahahahahah. Not really that funny. Guess what. I'm going to figure out how to mesh the hell out of that cathode region with salome. That's the next task! Hey at least stabilization helped that time!!! 

Note that the current Jacobian for the electrons for the Townsend formulation is absolutely wrong because I don't really know how to take the derivative of the absolute value of the flux. If the simulation fails because of this (pending that I can determine that that was indeed the cause of the failure), then I will invest some time into figuring out how to do that derivative correctly.

Running some simple tests, it looks like my scheme does indeed help stabilize. 

I went back to a local field formulation. And set a new world record for simulation time with (almost) all the physics included: Fail time = 1.92576e-5 seconds. Woooo! Hahaha. Going to add some stabilization for the ions because it looks like I'm getting some kinks and maybe some stabilization would help. I don't see any kinks in the electrons. 

Table of fail times for LFA formulation:
4000 elements. nl_rel_tol = 1e-2. Electron stabilization. Fail time = 1.92576e-5 (normal fail)
4000 elements. nl_rel_tol = 1e-2. Electron and ion stabilization. Fail time = 8.15811e-5 seconds (normal fail). New world record. Lots of oscillations in the electrons and ions, particularly the ions. This is likely without having a functional source term. But do those oscillations at really low concentration numbers matter? Because MOOSE is trying to minimize the residual, and in all places we are using the exponential of the concentration, or we are multiplying times the exponential of the concentration. 

I've added secondary electrons in and stuff is looking pretty damn good if I might say so myself. The problem is I got this error message after 3.8 microseconds (using ds for -mat_mffd_type):

[0]PETSC ERROR: Petsc has generated inconsistent data
[0]PETSC ERROR: Differencing parameter is not a number sum = nan dot = -nan norm = -nan
[0]PETSC ERROR: See http://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.

This error message occurred despite the fact that step sizes were still large, the previous time step's nonlinear solve had converged, and all the variable solutions were smooth. So if I can fix whathever problem caused the error message, I think the solver could keep going for quite a while. 

With -mat_mffd_type = wp, the simulation ran until 4.0 microseconds (so a little better). Solutions still looking smooth. This is the error message:

[0]PETSC ERROR: Petsc has generated inconsistent data
[0]PETSC ERROR: Computed Nan differencing parameter h
[0]PETSC ERROR: See http://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.

So slightly different error message. 

After scaling the potential by 1e13, the solve yielded the NaN differencing parameter at 3.071e-7 seconds (solve was proceeding well until that point.)

I changed the nl_rel_tol to 1e-3 (potential scaling still 1e13). With this setting, I incur a "normal" fail, e.g. no petsc errors. Solve failed at 3.3636e-6 seconds. Why did the solve fail? It's not because of the linear solve. In one of the later diverged non-linear solves, the linear residual is dropping just fine. However, the non-linear residual drops a couple orders of magnitude immediately but then refuses to drop any more. I don't know what the best strategy to approach this is. 

After scaling both the electrons and the ions by 1e2, the solve failed at 3.6097e-6 seconds, so a little later. Now when the solve is failing at the end of the simulation, the linear residuals are not dropping. Maybe this is a suggestion that I need to fix my preconditioner; well not fix, but add more terms and examine the petsc options for the preconditioner. 

I implemented all the Jacobian elements that I could think of and then switched to a Newton solve. The solve failed at 3.2548e-6 seconds. A normal fail with most of the crashes occurring because of diverged line search. Observe some oscillations where the electron temperature drops to zero in the mean_en plot. However, the mean_en is not the main contributor to the residual: the Arp kernel is. However, obviously em and Arp are both functions of mean_en and the electron temperature. However, the electron temperature actually looks smooth. The solve essentially fails as soon as the electron temperature touches zero. Is that a coincidence? I think not. 

Removing the ionization source term makes everything beautiful. The newton solve works beautifully...I get these nice giant implicit time steps. So it's the ionization source term that is gumming things up.

At the point where the mean_en goes to its small value, the value of mean_en - em is approximately -20...this will result in exp(-Eiz/(2/3*exp(mean_en - em))) having a value of 0, e.g. it's too small foating point value to be stored (I think). 

After going to 400 elements, the solve failed at 1.2209e-6 seconds. 

With the perfect preconditioner (finite difference preconditioner), the solve still failed. It failed at 5.8375e-6 seconds, so that is a world record. And what's interesting is that the electron temperature didn't touch zero as quickly. Two things left to try: 1) scale the potential residual. 2) Tighten the non-linear tolerance.

Scaled the potential residual: very interestingly the electron temperature touched down at zero earlier and the solve failed at 3.9943e-6 seconds as opposed to the much later time of 5.8375e-6 seconds without the potential scaling.

Last attempt: tighten the non-linear tolerance. After tightening the tolerances, the solve failed at 3.6947e-6 seconds. Again occurred immediately after touchdown of the electron temperature. I think it's safe to say that the problem is with my physics or with my residual implementation of the physics. I'm using a perfect preconditioner and a Newton solve, with smart choices for my relative and absolute tolerances. The problem is with the physics. 

I figured out why the source term wasn't having an effect on the solution: the pre-exponential factor simply wasn't large enough. If I increased it by two order of magnitude than the effects of the source were immediately apparent. Before making this change, I was using an alpha of 0.35 for air. How does that compare with number from bolos? It's incredibly small is what it is. For example, for an electric field of 1.5e7, alpha predicted by both bolos and bolsig is around 2e5. This is absurd compared to 0.35. 6 order of magnitude difference.

Yea, I solved this problem. Boom. Zapdos. Boom.

There's a lot of things to improve...for example Comsol took 10 minutes and 47 seconds to solve this problem on two processor. I believe that it took Zapdos 6 hours to solve on one processor. Sure, I could theoretically run Zapdos on many more processors, but then I need to fix my Jacobian. Comsol used a direct solver called MUMPS. I did not use a direct solver as far as I know. I would actually have to look at the default settings for Newton on one processor with a full preconditioning matrix formed from finite differencing of the residuals (I believe it's finite differencing of the residuals?). 

When I try to run with pc_type = lu, I get an error around the simulation time of 2.7e-5 seconds. The error is a petsc error and it says:
[0]PETSC ERROR: Zero pivot in LU factorization: http://www.mcs.anl.gov/petsc/documentation/faq.html#ZeroPivot
[0]PETSC ERROR: Zero pivot row 1 value 6.9212e-27 tolerance 2.22045e-14

I got this error twice. First time was with mat_fd_type = wp. Second time was with mat_fd_type = ds and with sub_pc_factor_shift = NONZERO. 

For p = 0, Discontinuous Galerkin is identical to first-order finite volume. That's really cool!

Trying the RF discharge. With default line search (I don't know what the default is, the moose list would lead me to believe that it's bt), the sim starts diverging at 3.63113e-8 seconds. With line_search = basic, the sim can't even take a single time step. Using line_search = cp, the sim starts diverging at t = 7.47679e-8 seconds. So I suppose that that's better. 

Reading the petsc manual, it looks like lu is the only direct solver available. To use it, use the options: -ksp_type=preonly; -pc_type=lu

From petsc manual: "Sometimes one is required to solve linear systems that are singular. That is systems with the matrix has a null space. For example, the discretization of the Laplacian operator with Neumann boundary conditions as a null space of the constant functions."

If trying to solve singular systems with direct solvers (or an incomplete factorization), it may still detect a zero pivot. Can run with additional options: -pc_factor_shift_type NONZERO -pc_factor_shift_amount <dampingfactor> to prevent the zero pivot. A good choice for the dampingfactor is 1.e-
10.

Files I need to fix after constructor update: RFIon, DCIon, RFElectron, DCElectron (both C and h files)

So for the RF plasma, keep in mind that I only calculated transport parameters for an electric field ranging from 1e3 to 1e6 V/m. There are problems with convergence for alpha with high electric fields (for this low pressure case of 1 torr). So after simulating, check and see whether the electric field stayed within those bounds. 

Here is Comsol's electron and electron energy stabilization terms:

N_A_const*exp(-Ne*ccp.zeta)*test(Ne)
N_A_const*exp(-En*ccp.zeta)*test(En)

Simple and elegant. Only becomes large when Ne or En is small. Remember that Ne and En are the log of the actual density and total electron energy. This can be easily implemented when I return to an energy equation formulation. (Hell it could be implemented right now if I wanted to). Zeta is a parameter set by the user. Please start using user parameters again.

Having a lot of problems with diverged line search when the solution approaches steady state.

We want to solve F<mat>(x<vec>) = 0 where F is a nonlinear system of equations. (n equations, n unknowns in x<vec>)

Newton's method: x_k+1<vec> = x_k<vec> - J_inverse<mat>(x_k<vec>) * F<mat>(x_k<vec>)

J = F_prime, e.g. the Jacobian is the derivative of F with respect to the system variables (x)

In order to use this method, the Jacobian must be invertible, e.g. it cannot be singular. Singular matrices cannot be inverted. 

Analytic expressions for the Jacobian can be provided by the user, or they can be calculated somewhat automatically (and approximately) by finite differencing F (the residuals). 

For a Newton solve in which the Jacobian elements are provided by the user, the -mat_fd_type makes no sense. The only time -mat_fd_type makes sense is when the Jacobian is calculated with finite differencing. One can also use a matrix free formulation, and then the option is -mat_mffd_type. 

To my mind the Jacobian and preconditioning matrices are two different matrices. But I'm not sure. 

Pre-conditioning is done in iterative linear solves. LU is a direct solver; it's a full inversion of the Jacobian matrix. Thus, if we're using LU, there is no preconditioning. 

From Wikipedia for solving the system:

A*x = b, we instead solve A*P_inverse*y = b, where y = P*x (right preconditioning) or P_inverse*(A*x-b) = 0 (left preconditioning, apparently more common). 

"Typically there is a trade-off in the choice of P. Since the operator P^{-1} must be applied at each step of the iterative linear solver, it should have a small cost (computing time) of applying the P^{-1} operation. The cheapest preconditioner would therefore be P=I since then P^{-1}=I. Clearly, this results in the original linear system and the preconditioner does nothing. At the other extreme, the choice P=A gives P^{-1}A = AP^{-1} = I, which has optimal condition number of 1, requiring a single iteration for convergence; however in this case P^{-1}=A^{-1}, and applying the preconditioner is as difficult as solving the original system. One therefore chooses P as somewhere between these two extremes, in an attempt to achieve a minimal number of linear iterations while keeping the operator P^{-1} as simple as possible. Some examples of typical preconditioning approaches are detailed below."

Thus to give the minimal number of linear iterations, P should equal A. (However, minimal number of linear iterations probably is not your only criteria for an efficient, accurate simulation). So A, wikipedia's notation, is actually the Jacobian in my problems. Thus the perfect preconditioner (in terms of least numer of linear iterations) for the linear solve, would actually be the Jacobian itself!; using the Jacobian itself would result in only one linear iteration. 

-snes_mf_operator: Activates default matrix-free Jacobian-vector products, and a user-provided preconditioning matrix as set by SNESSetJacobian() 

MOOSE delineates two things: the preconditioning matrix, and the preconditioning process. 

Oh, very interesting. Looking at the doco for SNESSetJacobian, there are two input matrices: A, the Jacobian matrix, and B, the preconditioner matrix, which "is usually the same as the Jacobian."

Thus Jed Brown's suggestion of using: "-snes_mf_operator -pc_type lu to see if the Jacobian you are
using is wrong." still doesn't make total sense to me. Ok, I think all of it is mostly making sense now. -snes_mf_operator activates default matrix-free Jacobian-vector products, and a user-provided preconditioning matrix as set by SNESSetJacobian(). As soon as we move to a matrix-free formulation, I believe we have to be using iterative linear solves. And that means using a preconditioner. How do we create the preconditioning matrix? By default it just uses the diagonals, e.g. whatever diagonal jacobian elements we've coded. Using SMP, full=true, we can say to build the entire preconditioning matrix, setting it equal (hopefully) to the Jacobian. However, we can also create the preconditioning matrix using finite differencing of the residual statements in the hope of creating a good approximation of the jacobian.

My hypothesis if I turn off the FDP preconditioner and use Jed's -snes_mf_operator -pc_type lu is that my preconditioning matrix will be formed from my diagonal jacobians (which are not well coded) and then I will be doing a "direct" matrix-free solve using lu. So I think that's what I saw; I saw some linear solves that were quite terrible. I hypothesize that that's because my preconditioning matrix was terrible. However, something that was quite interesting, and that makes me kind of happy, is that with Jed's options, it only took one non-linear iteration to solve the first time step. I'm not sure that I've seen that before. The solve failed at 2.94834e-6 seconds. Ok, now I'm going to try with Jed's options but with my preconditiong matrix set equal to the finite differenced jacobian. I'm hoping that this eliminates any bad linear solves. That's my hypothesis at least. 

When doing direct matrix solves, the Jacobian affects the nonlinear solution strategy. However, in matrix free solves, the Jacobian is not actually present. It's only loosely present in that you use some emulation of the Jacobian in constructing your preconditioner that's used in the linear iterative solve. So in a Newton matrix solve, the effect of the Jacobian will be pronounced in the non-linear steps. In a New matrix free solve, the effect of the Jacobian will be pronounced in the linear steps. So I could play around with -mat_mffd_type

I believe that in any matrix free formulation is going to involve finite differences and a differencing parameter. E.g. the action of the Jacobian on a vector is approximated using finite differences! So I believe I actually have two finite differencing operations coming into play: 1) I am constructing my Jacobian/Preconditionig matrix using finite differencing of my residuals. 2) Then I am approximating the action of my Jacoban/Preconditioning matrix on a vector using finite differences. #2 comes into play when I decide to go to a matrix free formulation. It's possible to have no finite differencing in your problem: 1) construct your jacobian using analytical expressions 2) don't use a matrix free formulation. Simulation using the FDP preconditioner seems quite stable. It would probably go all the way to completion if I let it run. First divergence occurred at 1.14239e-5 seconds. Going to go back to direct LU and see when first divergence occurs. With direct LU, first divergence occurs at 1.37097e-5 seconds, so a little better.

The default KSP type is GMRES with a restart of 30, using modified Gram-Schmidt orthogonalization. 

With default differencing parameter (I believe wp), here's Jacobian results:

Norm of matrix ratio 4.08771e-07 difference 0.0207982 (user-defined state)
Norm of matrix ratio 6.25133e-09 difference 8.56263e+09 (constant state -1.0)
Norm of matrix ratio 5.08948e-09 difference 9.62509e+08 (constant state 1.0)

With mat_fd_type=ds, Jacobian results:

Norm of matrix ratio 0.00932033 difference 474.28 (user-defined state)
Norm of matrix ratio 6.4317e-29 difference 8.80968e-11 (constant state -1.0)
Norm of matrix ratio 3.21208e-27 difference 6.0746e-10 (constant state 1.0)

With mat_fd_type=ds, mat_fd_coloring_err=1e-6, Jacobian results:

Norm of matrix ratio 7.87438e-05 difference 4.00641 (user-defined state)
Norm of matrix ratio 4.66307e-07 difference 6.38715e+11 (constant state -1.0)
Norm of matrix ratio 5.01161e-07 difference 9.47782e+10 (constant state 1.0)

I'm curious what the default mat_fd_coloring_err is, or if there is a default So if low numbers are generally better, maybe I should try ds? The two constant states are amazing but the user-defined state doesn't seem to be as good as wp. Again, I don't know what that means. -snes_type = test, can only be run if solve_type is set to NEWTON. It cannot be used JFNK. (matrix free methods). 

With ds, the solve first diverged at 1.37097e-5 seconds, so it appears to have been identical to wp. With mat_fd_coloring_err=1e-6, the solve crashed almost immediately. So that pretty well reflected the Jacobian results!

In the IntTD.C materials file, I took away eta, so all input files need to be free of an eta column.

So I've coded the Jacobians for the kernels; I forgot about the bloody boundary conditions!!!

A huge damn victory for Moose and Zapdos tonight!!!!!! Using my analytical jacobian, a Newton solve, a direct LU method, I solved the problem to steady state in 168 seconds :-) Take that comsol!!!!

Testing Jacobian after adding back in the Electron Energy equation. Hand-coded Jacobian:

Norm of matrix ratio 0.00756585 difference 384.97 (user-defined state)
Norm of matrix ratio 1.57362e-07 difference 2.15543e+11 (constant state -1.0)
Norm of matrix ratio 1.56667e-07 difference 2.96284e+10 (constant state 1.0)

FDP Jacobian:

Norm of matrix ratio 3.78445e-06 difference 0.192568 (user-defined state)
Norm of matrix ratio 1.21061e-07 difference 1.65821e+11 (constant state -1.0)
Norm of matrix ratio 1.22993e-07 difference 2.326e+10 (constant state 1.0)

Without BCs:

Norm of matrix ratio 0.00756585 difference 384.97 (user-defined state)
Norm of matrix ratio 1.57362e-07 difference 2.15543e+11 (constant state -1.0)
Norm of matrix ratio 1.56667e-07 difference 2.96284e+10 (constant state 1.0)

Without electron energy time derivative:

Norm of matrix ratio 0.00756608 difference 384.97 (user-defined state)
Norm of matrix ratio 1.57362e-07 difference 2.15543e+11 (constant state -1.0)
Norm of matrix ratio 1.56667e-07 difference 2.96284e+10 (constant state 1.0)

Without electron energy kernel:

Norm of matrix ratio 3.96561e-06 difference 0.201765 (user-defined state)
Norm of matrix ratio 1.57362e-07 difference 2.15543e+11 (constant state -1.0)
Norm of matrix ratio 1.56667e-07 difference 2.96284e+10 (constant state 1.0)

That last test kind of reveals where the error is, doesn't it?

After maybe modifying the source terms in the ElectronEnergyKernel:

Norm of matrix ratio 0.00756585 difference 384.97 (user-defined state)
Norm of matrix ratio 1.57362e-07 difference 2.15543e+11 (constant state -1.0)
Norm of matrix ratio 1.56667e-07 difference 2.96284e+10 (constant state 1.0)

After removing Joule heating:

Norm of matrix ratio 0.00756585 difference 384.97 (user-defined state)
Norm of matrix ratio 1.57362e-07 difference 2.15543e+11 (constant state -1.0)
Norm of matrix ratio 1.56667e-07 difference 2.96284e+10 (constant state 1.0)

After removing all but advection and diffusion:

Norm of matrix ratio 9.24413e-06 difference 0.470329 (user-defined state)
Norm of matrix ratio 1.57362e-07 difference 2.15543e+11 (constant state -1.0)
Norm of matrix ratio 1.56667e-07 difference 2.96284e+10 (constant state 1.0)

Same but using FDP:

Norm of matrix ratio 3.78303e-06 difference 0.192476 (user-defined state)
Norm of matrix ratio 1.21061e-07 difference 1.65821e+11 (constant state -1.0)
Norm of matrix ratio 1.22993e-07 difference 2.326e+10 (constant state 1.0)

With all physics in ElectronEnergyKernel removed:

Norm of matrix ratio 3.96561e-06 difference 0.201765 (user-defined state)
Norm of matrix ratio 1.57362e-07 difference 2.15543e+11 (constant state -1.0)
Norm of matrix ratio 1.56667e-07 difference 2.96284e+10 (constant state 1.0)

Two things to do:
1) Make a couple of results summary slides of what I've done so far in Zapdos
2) 5 modules (kernels, BCs) I would want to add to make Zapdos/Moose relevant for broader LTP community

The steady state electron density as determined by zapdos does not differ based on whether an iterative or direct solve is used. The peak electron density for zapdos (both direct and iterative solutions) and the peak electron density for comsol differ by 5.1% (Which is actually fairly significant I suppose). 

MKL PARDISO: Intel Math Kernel Library PARallel Direct SOlver

PARDISO in Intel MKL was originally developed by the Department of Computer Scienc at the University of Basel. It can be obtained at http://www.pardiso-project.org

After adding back in advection and diffusion and on-diagonal jacobians. I've reviewed these residuals and jacobians and they are exactly correct.

Norm of matrix ratio 7.10444e-06 difference 0.361464 (user-defined state)
Norm of matrix ratio 1.57362e-07 difference 2.15543e+11 (constant state -1.0)
Norm of matrix ratio 1.56667e-07 difference 2.96284e+10 (constant state 1.0)

After adding back advection off-diag jacobian. After review, this looks perfect.

Norm of matrix ratio 9.24413e-06 difference 0.470329 (user-defined state)
Norm of matrix ratio 1.57362e-07 difference 2.15543e+11 (constant state -1.0)
Norm of matrix ratio 1.56667e-07 difference 2.96284e+10 (constant state 1.0)

After adding in Joule-heating and associated potential off-diag jacobian:

Norm of matrix ratio 9.24413e-06 difference 0.470329 (user-defined state)
Norm of matrix ratio 1.57362e-07 difference 2.15543e+11 (constant state -1.0)
Norm of matrix ratio 1.56667e-07 difference 2.96284e+10 (constant state 1.0)

After adding in Joule-heating and associated em off-diag jacobian:

Norm of matrix ratio 9.24413e-06 difference 0.470329 (user-defined state)
Norm of matrix ratio 1.57362e-07 difference 2.15543e+11 (constant state -1.0)
Norm of matrix ratio 1.56667e-07 difference 2.96284e+10 (constant state 1.0)

After adding back reaction source and on-diag jacobian:

Norm of matrix ratio 0.00756587 difference 384.97 (user-defined state)
Norm of matrix ratio 1.57362e-07 difference 2.15543e+11 (constant state -1.0)
Norm of matrix ratio 1.56667e-07 difference 2.96284e+10 (constant state 1.0)

When trying to solve using super lu, I keep getting diverged_line_search after 0 iterations when I use the default line search. If I set line_search='none', then the initial divergence occurs at (at least approximately) the same time step, but the divergence message is: diverged_fnorm_nan. 

When solving in parallel with moose's default parallel iterative options, the solve fails at 1.69359e-7 seconds. The final divergence reason is given by:

  Linear solve did not converge due to DIVERGED_NANORINF iterations 0
Nonlinear solve did not converge due to DIVERGED_LINEAR_SOLVE iterations 2

Looking at all the divergences, the DIVERGED_LINEAR_SOLVE was about as frequent as DIVERGED_LINE_SEARCH.

Just confirming that in this test problem the Jacobian is good, when I run the fast_solve_parallel_iterative_attempt in test mode, with a mesh size of 1, here's what the results look like:

Norm of matrix ratio 4.44187e-08 difference 0.00226001 (user-defined state)
Norm of matrix ratio 2.33137e-08 difference 3.19335e+10 (constant state -1.0)
Norm of matrix ratio 2.20073e-08 difference 4.16197e+09 (constant state 1.0)

So excellent. When I change the mesh size to 100, here are the results (still good):

Norm of matrix ratio 1.58941e-07 difference 0.00808669 (user-defined state)
Norm of matrix ratio 3.48091e-08 difference 4.7679e+10 (constant state -1.0)
Norm of matrix ratio 3.26732e-08 difference 6.17907e+09 (constant state 1.0)

What am I trying to do right now? I'm trying to get my gold_serial_case to solve in parallel mode, using 1) iterative methods and 2) direct methods. Another thing that I've been working on is adding back an electron energy equation; I'm currently debugging the Jacobian for that.

I'm looking at the iterative solve right now. If I run with one mesh element, I get a floating point exception which appears to occur at line 52 in ElectronKernel.C. However, if I run with 100 mesh elements, than I no longer get any FPEs/program breaks when running ./zapdos-dbg (without gdb --args). So the FPE does indeed come from an exponential overflow. The last value of _u[_qp] before the floating point exception is signalled is: 7.88655e+07. Since I know that exp(1000) produces inf, then obviously 7.89e7 will also produce an inf. This exercise kind of just goes to show that you need an appropriate number of mesh elements or else your solution will have major problems.

I ran the direct solve with one mesh element (./zapdos-dbg) and got no FPEs.

Don't forget how to print values in the debugger:

p <variable>

or 

print <variable>

Ok, using default MOOSE iterative with mpirun and an abs tolerance of 1e-6 (e.g. all the parameters the same from the fast serial lu gold solve except for the solve type), the solve fails at 2.49633e-07 seconds. All the divergence reasons are: DIVERGED_LINE_SEARCH. First divergence occurs at: 4.84966e-08 seconds. No line_search option specified for the settings in this passage (so default). Now the iterative solve has major problems with its solution variables, and this could easily explain why this solve fails. There are clear spikes at L/4, L/2, and 3L/4 in the dependent variable Arp and in the auxiliary variable EField. So again, parallel iterative solves are failing. 

Using direct super LU with line_search='none', first divergence is at 1.28117e-07 seconds, and the message is DIVERGED_FNORM_NAN. All the divergence messages are DIVERGED_FNORM_NAN. Final failure occurs at 2.40013e-07 seconds. (So fairly comparable to the iterative attempt). With default line_serach, first divergence is identically at 1.28117e-07 seconds. All divergence reasons are DIVERGED_LINE_SEARCH. Final failure identically occurs at 2.40013e-07 seconds. So my initial intuitive reaction was correct: despite the change in line_search, the solve patterns are the exact same. Looking at the default line search results in paraview, every solution variable looks just fine at the premature end of the simulation: all variable profiles are smooth and continuous, so any reason for the solve fail can't really be found there.

The fun part now in both direct and iterative cases is to figure out: what's causing the diverged line search???

Alright, doing some cool stuff. Did a serial iterative solve. | Zapdos Performance: Alive time=150.776, Active time=149.795. pc_type=ilu, ksp_type=gmres, snes_type=newtonls. Results look perfect. 

With pc_type=gamg, the problem wasn't even able to take a single time step.

hypre is meant for massively parallel computing (taken from its homepage). 

With pc_type=asm, sub_pc_type=ilu, the problem solves. Solution summary: | Zapdos Performance: Alive time=159.017, Active time=158.009. 

With:

  petsc_options_iname = '-pc_type -sub_pc_type -sub_pc_factor_shift_type -sub_pc_factor_shift_amount'
  petsc_options_value = 'asm lu NONZERO 1.e-10'

Solution summary: | Zapdos Performance: Alive time=153.569, Active time=152.56

With pc_type=bjacobi, the problem solves. Solution summary: | Zapdos Performance: Alive time=149.462, Active time=148.471 (Record)

Next step: try suggestions from petsc email for direct solves.

This should be my compiler environment the next time I update_and_rebuild libmesh and recompile MOOSE and Zapdos:
export CC="ccache mpicc"
export CXX="ccache mpicxx"
export CCACHE_SLOPPINESS=time_macros

Oh heck yea: solved my problem in parallel!!!!!!!!! Wooooooooooooooooooooooo!!!!!!!!!!!!!!!!! Got mumps working correctly and it solved like a bloody damn champion. To summarize here were the petsc options:

  petsc_options_iname = '-pc_type -pc_factor_shift_type -pc_factor_shift_amount -ksp_type -pc_factor_mat_solver_package'
  petsc_options_value = 'lu NONZERO 1.e-10 preonly mumps'

And here is the execution summary: | Zapdos Performance: Alive time=133.099, Active time=131.212

So having the parallel solve didn't really speed up the solution, but it's a demonstration of principle gosh darn it!!!

Ok, this is really freaking weird. I went back to an old commit where there was no ZapdosRevision.h file, but presumably there should have been no new source code changes to compile, and when I typed make -j4, here's the first output: 

MOOSE Generating Header /home/lindsayad/projects/zapdos/include/ZapdosRevision.h...

Then it proceeds to compile zapdos source files (presumably it was going to compile all of them before I manually stopped it.)

However, when I reset my pointer to point at the newest commit (where ZapdosRevision.h is included), it still recompiled all my source code, only this time it didn't have that first line: 

MOOSE Generating Header /home/lindsayad/projects/zapdos/include/ZapdosRevision.h...

It's important to note that after recompilation, my gold mumps script executed without complaint, so that helps to assuage some of my fears that recompilation would prevent me from seeing petsc packages.

Using parallel Bjacobi with lu as the sub_pc_type, the solve failed at 2.35183e-07 seconds. And sure enough, I see the familiar kinks in the solution in the places where the processors come together. This was done on 4 processors.

However, when I went to 2 processors the problem solved! Performance summary: | Zapdos Performance: Alive time=111.615, Active time=110.712 (Record!)

In early time steps, I could still see some kinks in the Arp solution and occasionally even in the em solution. However, at longer time steps the kinks disappeared. I would hypothesize that these kinks only appear when the potential is almost perfectly linear and the electric field is incredibly uniform such that any tiny miscommunication between the processors will induce a very noted change in the electrostatics on an automatic scale. And these kinks in the electrostatics directly impact the particle drift motion. However, on longer time scales when the particles begin to affect the electric field, these affects are much stronger and on a much larger scale than the processor miscommunication so that the processor miscommunication no longer becomes a problem.

With that same run as the one immediately above on the desktop, the problem solved in 97 seconds with console output to the screen. When I tried running with 4 processors, I got the same crash that I've come to know. It also occurred at 2.35183e-07 seconds. So the success of running on 2 cores comes not from having the correct number of physical cores but from the formulation of the problem.

Reducing the amount of output to the log file doesn't seem to have helped the problem solve any faster. Scaling comparison:

2 processors: 97.0632 seconds
1 processor: 141.503 seconds

So computation time was reduced by 31%. E.g. it took 69% as long with 2 processors as it did with 1. With perfect parallelization that 69 number would be 50.

Here's the Jacobian test output for this ionization source residual and corresponding Jacobian: 

    -_test[_i][_qp]*_rate_coeff_ion_en[_qp]*_Ar[_qp]*-_Eiz_en[_qp]*_em[_qp]

Norm of matrix ratio 7.86836e-08 difference 0.00400463 (user-defined state)
Norm of matrix ratio 1.76423e-08 difference 2.41652e+10 (constant state -1.0)
Norm of matrix ratio 1.9803e-08 difference 3.74509e+09 (constant state 1.0)

Here's the Jacobian test output for this ionization source residual and corresponding Jacobian: 

    -_test[_i][_qp]*_rate_coeff_ion_en[_qp]*_Ar[_qp]*-_Eiz_en[_qp]*_em[_qp]*em[_qp]

Norm of matrix ratio 7.86836e-08 difference 0.00400463 (user-defined state)
Norm of matrix ratio 1.76423e-08 difference 2.41652e+10 (constant state -1.0)
Norm of matrix ratio 1.9803e-08 difference 3.74509e+09 (constant state 1.0)

Here's the Jacobian test output for this ionization source residual and corresponding Jacobian: 

    -_test[_i][_qp]*_rate_coeff_ion_en[_qp]*_Ar[_qp]*-_Eiz_en[_qp]*std::sqrt(_em[_qp])

Norm of matrix ratio 7.86834e-08 difference 0.00400462 (user-defined state)
Norm of matrix ratio -nan difference -nan (constant state -1.0)
Norm of matrix ratio 1.9803e-08 difference 3.74509e+09 (constant state 1.0)

Here's the Jacobian test output for this ionization source residual and corresponding Jacobian: 

    -_test[_i][_qp]*_rate_coeff_ion_en[_qp]*_Ar[_qp]*-_Eiz_en[_qp]*std::exp(_em[_qp])

Norm of matrix ratio 1.45574 difference 74090.6 (user-defined state)
Norm of matrix ratio 1.76423e-08 difference 2.41652e+10 (constant state -1.0)
Norm of matrix ratio 1.9803e-08 difference 3.74509e+09 (constant state 1.0)

Here's the Jacobian test output for this ionization source residual and corresponding Jacobian: 

    -_test[_i][_qp]*_rate_coeff_ion_en[_qp]*_Ar[_qp]*-_Eiz_en[_qp]*std::exp(_u[_qp])

Norm of matrix ratio 4.08685e-08 difference 0.0123279 (user-defined state)
Norm of matrix ratio 1.76423e-08 difference 2.41652e+10 (constant state -1.0)
Norm of matrix ratio 1.9803e-08 difference 3.74509e+09 (constant state 1.0)

I think I'm figuring out what the constant states mean in the Jacobian test. I believe that constant state 1.0 is where all the dependent variables are set to 1.0 (an IC). User-defined state would be with my defined ICs. Yes my hypothesis is confirmed. So if I set all my variables to ICs of 1 or -1, my Jacobian looks really damn good!

It should also be noted that the variable scaling affects the "Norm of matrix ratios."

Trying with electron energy formulation again. Solve failed at 1.05637-07 seconds. All the variables look pretty nice and smooth, so I don't really know what the problem is. Divergence reasons were fairly evenly split between diverged_max_its and diverged_line_search. At the last convergence step, here were the variable residual norms:

                  potential: 4.042e-10
                  em:        2.6627e-08
                  Arp:       3.20928e-10
                  mean_en:   0.000475877

With an abs_tolerance=1e-2 and using mumps in parallel, the solve still failed at 1.05637e-07 seconds. With the ionization source terms elimination in the electron energy equation, the solve actually failed earlier at 7.59991e-08 seconds. This actually makes since because I still have physical production of electrons and ions in their respective kernels. Dumb me.

Tried again with electron energy formulation, but using PJFNK instead of NEWTON. Solve got a bit farther this time: failed at 3.39951e-07 seconds. Instead of any DIVERGED_LINE_SEARCH, all fails were due to DIVERGED_MAX_IT. i think diverged_line_search only really appears when doing Newton solves. The only reason it went farther is because I forgot to turn the ionization terms in the em and ion kernels back on again. With those turned back on, the solve fails at 1.08282e-07 seconds. Again, looking at the solution variables, I can see no reason why the solve should fail. However, if I look at the log, the linear residuals don't seem to be coming down nearly fast enough, suggesting to my continued bewilderment, that my Jacobian is somehow wrong. I'm going to try to solve using FDP.

Using FDP and a direct LU solve, the solve failes at 1.113e-07 seconds. Record, wooo! Haha...no. Why the hell does it fail? All the variables are gosh darn smooth! I don't see any oscillations anywhere!

With block-jacobi:

 9 Nonlinear |R| = 5.601308e-06
Nonlinear solve converged due to CONVERGED_FNORM_RELATIVE iterations 9
 Solve Converged!

With asm:

 9 Nonlinear |R| = 5.601308e-06
Nonlinear solve converged due to CONVERGED_FNORM_RELATIVE iterations 9
 Solve Converged!

So I have no bloody idea whether my command line petsc options are working. Actually it most certainly appears to not be working because when I pass -ksp_type=preonly on the command line, linear iterations still appear in the log file. Petsc options are still working from the input file, however. Another thing that appears to not be working is that when I pass the -help option on the command line, the values that appear in <> for the petsc variables don't represent the values being used in my program. Rather they appear to represent the defaults. This is strange because I feel like I have a memory of being able to see my values represented in <>. 

I see the same behavior on my laptop. Perhaps it's a petsc version thing. Perhaps with version 3.5.x of petsc I could see the values of the variables I had changed instead of the defaults. It would be quite nice to confirm that I've changed the variables that I think I've changed.

With initial values of 1e17, the simulation fails at 8.81971e-08 seconds, so worse. With initial value of 1e7, the simulation fails at 1.26705e-07 seconds, so better. The reason for crashing has to be has to be boundary conditions. With my diffusion stabilization, the crash occurs at the same time: 1.26705e-07 seconds. I'm speculating that it's the electron energy boundary condition.

I changed the electron energy boundary condition in such a way that I would have assumed it would make a zero gradient boundary condition at both boundaries, but that didn't happen. In fact absolutely nothing appears to have changed. Solve still failed at 1.26705e-07 seconds. Changed to Neumann BCs for the electron energy. This did not change the fail time, but there were more oscillations at the right boundary...this doesn't surprise me since this BC change prevented energy from flowing out of the right boundary which it wants to be able to do. It's like a log jam with stuff piling up, leading to the oscillations. Remember, always try to make the problem as simple as possible!!!

Alright, so what I did is I left only the Joule heating and ionization energy loss terms in the Electron Energy Formulation, meaning that there's no energy loss from elastic collisions and there's no energy motion, negating the need for electron energy boundary conditions. The resulting simulation lasted a tiny bit longer: 1.29151e-07 seconds. Next flub: increase the ion mobility and diffusivity and see whether that removes the ion oscillations at the right boundary; i.e. also determine whether the ion oscillations might be responsbile for the simulation failures. I would think not, but can't know until we try. 

Oh yes, in case I forgot to note this to myself: the fact that this problem won't solve even with the "theoretically perfect" Jacobian generated by FDP could mean that my hand coded Jacobians are not the reason for the failure of my hand coded runs.

With ion mobility and diffusivity increasd by 100 fold, the simulation lasted until 1.33596e-07 seconds. Improvement! Haha. The ion oscillations at the right boundary disappeared only to be replaced with electron oscillations. And interestingly the electric field magnitude increased in that anode region. Next thing I'm trying is decreasing the max voltage by a factor of 10, e.g. to 1e4. This seems to have done the trick. Currently the simulation is at 1e-4 seconds and still powering away. VERY IMPORTANT NOTE: the two unphysical things I think I currently have in this apparently successful simulation are: 1) the electron energy boundary condition is allowing energy to flow in (I think) 2) the ion mobility and diffusivity are a factor of 100 higher than what I've used in the past.

The problem did in fact solve. Boom goes the dyanamite. Dropping the mike :-)  Alive time: 26489.3 seconds, corresponding to 7.358 hours. 

I tried going back to SMP formulation, and the solve failed at 8.28004e-07 seconds. Other changes I made other than just going back to SMP: I restored the ion transport coefficients to their default values, and I reduced the absolute tolerance to 1e-5.

Uhhhhh.....somehow my Jacobian is correct now? That would make no bloody sense. This is exceedingly mysterious to me but here are the results:

Norm of matrix ratio 4.58232e-08 difference 233.939 (user-defined state)
Norm of matrix ratio 1.32657e-08 difference 1.66194e+09 (constant state -1.0)
Norm of matrix ratio 1.54792e-08 difference 3.20123e+08 (constant state 1.0)

I don't think I changed a single thing to make this happen. Apparently reducing the potential_bc_func reduces the norm of the matrix-ratio of the user-defined state. 

For potential = 1e3: Norm of matrix ratio 3.2554e-08 difference 23.3871 (user-defined state)
For pot = 1e4: Norm of matrix ratio 4.58232e-08 difference 233.939 (user-defined state)
For pot = 1e5: Norm of matrix ratio 4.64405e-08 difference 2359.25 (user-defined state)

With potential at 5e3, solve failed at 1.6731e-06 seconds, so better. 
With potential at 1e3, the solve succeeded but only because the potential was below breakdown.

Maybe there could have been one thing different about my Jacobians: I had _a set to 1.0 for all boundaries in the Electron energy boundary condition source file. This is a change that should be in my simulation, but it's too far along right now for me to want to stop it. 

1 mesh element, 4 processors: Norm of matrix ratio 2.05868e-08 difference 11.6923 (user-defined state)
4 mesh elements, 4 processors: Norm of matrix ratio 2.35982e-08 difference 13.4026 (user-defined state)
4 mesh elements, 1 processor, mpirun: Norm of matrix ratio 2.35982e-08 difference 13.4026 (user-defined state)
4 mesh elements, 1 processor, no mpirun: Norm of matrix ratio 2.35982e-08 difference 13.4026 (user-defined state)

Woooooooooooooooooooooooooooooooooooooooooooooooooooooo!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! This truly represents the conquering of one of my bullet points in my MOOSE strategic plan. I got the electron energy formulation problem to solve in ~11 minutes :-) What was the trick? There's always a trick...the trick was to do as is oft repeated on the Moose discussion forum: don't allow outlier residual norms. Previously, my electron energy residual was 5 orders of magnitude larger than my em residual. After scaling it back by 5 orders of magnitude, I saw the orders of magnitude speed-up in my calculation. When I went back and solved in this manner, the active time was 864.56 seconds, corresponding to 14.4 minutes (this time I actually printed a performance log so 14.4 minutes should be taken as being the correct time compared to 11 minutes). 

Perhaps the only thing that I can anticipate people complaining about is that I'm only applying 350 Volts over 1 cm: 3.5e2/1e-2 = 3.5e4 V/m. In Go's paper, he uses 210 V/1 mm = 2.1e2/1e-3 = 2.1e5 V/m. Reasons to explain this discrepancy: no possible attachment or recombination processes included in my model. Also, the transport/rate coefficient parameters were somewhat arbitrarily chosen.

So I see that my CoupledIntegratedBC is apparently having absolutely zero effect. Having the matched values BC causes v to match the value of u. u is 1 in it's whole domain (block 0). If the matched values BC is not active, then v is 0 everywhere in its domain.

From DGKernel.h: "The DGKernel class is responsible for calculating the residuals for physics on internal sides (edges/faces)."

Assembly::elemVolume(): Returns the reference to the current element volume
Assembly::elem(): Returns the current element 
Assembly::side(): returns the current side
Assembly::neighborSide(): returns the current neighboring side
Assembly::sideElemVolume(): returns reference to the volume (or length [I believe that sideElemVolume should have units of Area if elemVolume has units of Volume, units of Length if elemVolume has units of Area, and be equal to one if elemVolume has units of Length. If that belief is true, then this calculation would have units of Length: h_elem = _current_elem->volume()/_current_side_elem->volume() * 1./std::pow(elem_b_order, 2.) which would make sense.]) of current side element
Assembly::neighborVolume(): returns reference to current neighbor volume

I think I'm starting to get an idea of what I need to do. I need to be able to pass a side (the only side in my interfacial case) that I want the DGKernel to act on. I need this kernel to have access both to u on the "inside" and to the coupled_var on the "outside." And in my particular case I want to know _grad_u at the "inside" side, and _grad_coupled_var at the "outside" side. Let's go explore IntegratedBC to see how one might access the values of those parameters (_u, _grad_u, _coupled_var, _grad_coupled_var) on sides (boundaries).

Here's constructor in KernelBase.C:

    MooseObject(parameters),
    BlockRestrictable(parameters),
    SetupInterface(parameters),
    CoupleableMooseVariableDependencyIntermediateInterface(parameters, false),
    FunctionInterface(parameters),
    UserObjectInterface(parameters),
    TransientInterface(parameters, "kernels"),
    PostprocessorInterface(parameters),
    MaterialPropertyInterface(parameters, blockIDs()),
    RandomInterface(parameters, *parameters.get<FEProblem *>("_fe_problem"), parameters.get<THREAD_ID>("_tid"), false),
    GeometricSearchInterface(parameters),
    Restartable(parameters, "Kernels"),
    ZeroInterface(parameters),
    MeshChangedInterface(parameters),
    _subproblem(*parameters.get<SubProblem *>("_subproblem")),
    _fe_problem(*parameters.get<FEProblem *>("_fe_problem")),
    _sys(*parameters.get<SystemBase *>("_sys")),
    _tid(parameters.get<THREAD_ID>("_tid")),
    _assembly(_subproblem.assembly(_tid)),
    _var(_sys.getVariable(_tid, parameters.get<NonlinearVariableName>("variable"))),
    _mesh(_subproblem.mesh()),
    _current_elem(_var.currentElem()),
    _current_elem_volume(_assembly.elemVolume()),
    _q_point(_assembly.qPoints()),
    _qrule(_assembly.qRule()),
    _JxW(_assembly.JxW()),
    _coord(_assembly.coordTransformation()),

    _test(_var.phi()),
    _grad_test(_var.gradPhi()),

    _phi(_assembly.phi()),
    _grad_phi(_assembly.gradPhi()),

Here's constructor in DGKernel.C:

    MooseObject(parameters),
    SetupInterface(parameters),
    TransientInterface(parameters, "dgkernels"),
    FunctionInterface(parameters),
    UserObjectInterface(parameters),
    NeighborCoupleableMooseVariableDependencyIntermediateInterface(parameters, false, false),
    TwoMaterialPropertyInterface(parameters),
    Restartable(parameters, "DGKernels"),
    MeshChangedInterface(parameters),
    _subproblem(*parameters.get<SubProblem *>("_subproblem")),
    _sys(*parameters.get<SystemBase *>("_sys")),
    _tid(parameters.get<THREAD_ID>("_tid")),
    _assembly(_subproblem.assembly(_tid)),
    _var(_sys.getVariable(_tid, parameters.get<NonlinearVariableName>("variable"))),
    _mesh(_subproblem.mesh()),

    _current_elem(_assembly.elem()),
    _current_elem_volume(_assembly.elemVolume()),

    _neighbor_elem(_assembly.neighbor()),
    _neighbor_elem_volume(_assembly.neighborVolume()),

    _current_side(_assembly.side()),
    _current_side_elem(_assembly.sideElem()),
    _current_side_volume(_assembly.sideElemVolume()),

    _coord_sys(_assembly.coordSystem()),
    _q_point(_assembly.qPointsFace()),
    _qrule(_assembly.qRuleFace()),
    _JxW(_assembly.JxWFace()),
    _coord(_assembly.coordTransformation()),

    _boundary_id(parameters.get<BoundaryID>("_boundary_id")),

    _u(_var.sln()),
    _grad_u(_var.gradSln()),

    _phi(_assembly.phiFace()),
    _grad_phi(_assembly.gradPhiFace()),

    _test(_var.phiFace()),
    _grad_test(_var.gradPhiFace()),

    _normals(_var.normals()),

    _phi_neighbor(_assembly.phiFaceNeighbor()),
    _grad_phi_neighbor(_assembly.gradPhiFaceNeighbor()),

    _test_neighbor(_var.phiFaceNeighbor()),
    _grad_test_neighbor(_var.gradPhiFaceNeighbor()),

    _u_neighbor(_var.slnNeighbor()),
    _grad_u_neighbor(_var.gradSlnNeighbor())

Here's constructor in IntegratedBC:

    BoundaryCondition(parameters),
    RandomInterface(parameters, _fe_problem, _tid, false),
    CoupleableMooseVariableDependencyIntermediateInterface(parameters, false),
    MaterialPropertyInterface(parameters),
    _current_elem(_assembly.elem()),
    _current_elem_volume(_assembly.elemVolume()),
    _current_side(_assembly.side()),
    _current_side_elem(_assembly.sideElem()),
    _current_side_volume(_assembly.sideElemVolume()),

    _normals(_var.normals()),

    _qrule(_assembly.qRuleFace()),
    _q_point(_assembly.qPointsFace()),
    _JxW(_assembly.JxWFace()),
    _coord(_assembly.coordTransformation()),

    _phi(_assembly.phiFace()),
    _grad_phi(_assembly.gradPhiFace()),

    _test(_var.phiFace()),
    _grad_test(_var.gradPhiFace()),

    _u(_is_implicit ? _var.sln() : _var.slnOld()),
    _grad_u(_is_implicit ? _var.gradSln() : _var.gradSlnOld()),

Conclusion: A buttload of similarities between DGKernel and IntegratedBC

I can do something exceedingly stupid. If I could set it up to determine whether a side is on the internal boundary, then the residual is non-zero. However, if the side is not on the boundary, then I set the residual to zero. Things I need to figure out:

1) How to tell whether a side is on a boundary
2) How to access a variable from another block

const std::vector<DGKernel *>& DGKernelWarehouse::active() ====> Get the list of all active kernels

void ComputeResidualThread::onInternalSide(const Elem * elem, unsigned int side) ===> elem: element we are on. Side: Local side number of the element 'elem'. Hmm local number may not be very helpful

ComputeResidualThread.C is where the magic happens. Here are three straight function definitions in the file:

ComputeResidualThread::onElement(const Elem *elem)
ComputeResidualThread::onBoundary(const Elem *elem, unsigned int side, BoundaryID bnd_id)
ComputeResidualThread::onInternalSide(const Elem *elem, unsigned int side)

onElement goes to the KernelWarehouse
onBoundary goes to the BCWarehouse and looks for active IntegratedBCs
onInternalSide goes to the DGKernelWarehouse

Here are the includes at the start of ComputeResidualThread:

#include "ComputeResidualThread.h"
#include "NonlinearSystem.h"
#include "Problem.h"
#include "FEProblem.h"
#include "KernelBase.h"
#include "IntegratedBC.h"
#include "DGKernel.h"
#include "Material.h"
// libmesh includes
#include "libmesh/threads.h"

Some member variables of ComputeResidualThread: _sys(sys), _kernel_type(type), _num_cached(0)

ComputeResidualThread also inherits from ThreadedElementLoop. ThreadedElementLoop inherits from ThreadedElementLoopBase. 

THREAD_ID ThreadedElementLoopBase<RangeType>::_tid

To get active integrated boundary conditions, we call BCWarehouse::activeIntegrated(BoundaryID boundary_id, std::vector<IntegratedBC*>& active_integrated)

And here's the function content:
{
  active_integrated.clear();

  if (_bcs.find(boundary_id) != _bcs.end())
    for (std::vector<IntegratedBC *>::const_iterator it = _bcs.at(boundary_id).begin(); it != _bcs.at(boundary_id).end(); ++it)
      if ((*it)->isActive())
        active_integrated.push_back(*it);
}

std::map<BoundaryID, std::vector<IntegratedBC *> > BCWarehouse::_bcs

std::map has member functions end, find, begin, etc.
find: get iterator to element
begin: return iterator to beginning
end: return iterator to end
at: access element
All of the above are public member functions

 _sys.getBCWarehouse(_tid).activeIntegrated(bnd_id, bcs);
std::vector<DGKernel *> dgks = _sys.getDGKernelWarehouse(_tid).active();

The warehouses are important. In DGKernelWarehouse.C, the following member functions are defined: initialSetup, timestepSetup, residualSetup, jacobianSetup, addDGKernel(MooseSharedPointer<DGKernel> & dg_kernel), updateActiveDGKernels(Real /*t*/, Real /*dt*/)

const std::vector<DGKernel *> & active() const { return _active_dg_kernels; }

void
DGKernelWarehouse::updateActiveDGKernels(Real /*t*/, Real /*dt*/)
{
  _active_dg_kernels.clear();

  // add kernels that live everywhere
  for (std::vector<DGKernel *>::const_iterator it = _all_objects.begin(); it != _all_objects.end(); ++it)
  {
    DGKernel * dg_kernel = *it;
    // FIXME: add startTime/stopTime to DGKernel
//    if (dg_kernel->startTime() <= t + (1e-6 * dt) && dg_kernel->stopTime() >= t + (1e-6 * dt))
      _active_dg_kernels.push_back(dg_kernel);
  }
}

Following down the trail. Now pursuing _all_objects

_all_objects: All instances of objects (raw pointers)

onBoundary parameters:

elem : The element we are checking is on the boundary
side : The side of the element in question
bnd_id : ID of the boundary we are at

onBoundary gets called when doing boundary assembling

I might have been wrong about where the magic happens. The magic might happen in NonlinearSystem::computeResidual. I may return to this, but from Yaqi it sounds like Mortar could be what I need. 

Sideset and nodeset naming are described in the MOOSE FAQ. 

FaceFaceConstraint has available Params: "variable" ==> This is substituted with Lagrange multiplier; "master_variable" ==> This is the variable on the master side of the mortar interface, e.g. 'u'; "slave_variable" ==> This is the variable on the slave side of the mortar interface, e.g. 'v', however, if the "slave_variable" is not specified, then it is set to "master_variable".  Very cool

 NeighborCoupleable(parameters, nodal, neighbor_nodal)

nodal and neighbor_nodal are both of type bool. 

NodeFaceConstraint actually has _grad in it

EqualValueConstraint inherits from FaceFaceConstraint
TiedValueConstraint inherits from NodeFaceConstraint
CoupledTiedValueConstraint also inherits from NodeFaceConstraint

getValue comes from the MooseVariable class

There are three fundamental constraints in the moose framework:

NodalConstraint
NodeFaceConstraint
FaceFaceConstraint

FaceFaceConstraint has to be the most natural fit for what I want to do right??????

NodeFaceConstraint has a grad definition. Nodal and FaceFace do not. The derivatives of NodeFaceConstraint are TiedValueConstraint and CoupledTiedValueConstraint. Neither of these have grad in them. None of the module source files that inherit from NodeFaceConstraint have grad in them either. 

I think that I need to think about C++, arrays, and initialization. After declaration, access the values of the arrya using:

name[index]

MooseVariable::gradSln() returns _grad_u, e.g. it returns a VariableGradient

What does it mean when I do _grad_u_master[_qp] = _master_var.gradSln() ??

That just doesn't seem right to me.

It appears that my MeshModifier sidesets and nodesets don't get created until after my application is executed. E.g. they don't appear in peacock_run_tmp_mesh.e

Yes it appears that in the mesh file for conforming_two_var.i, there is a pre-existing subdomain called "Unnamed block ID: 1000 Type: EDGE2"

Recall that these mesh files are in the exodus format

After executing the conforming_two_var.i file, the mortar subdomain simply becomes "middle" which is its short name.

It's become apparent that SubdomainBoundingBox only works if you draw a box, e.g. you cannot try and pass a line and try and build a subdomain with it.

It looks like I either need to use an external package or write some new MooseModifier code. 

I need type EDGE2

By default, when salome exports a mesh, it doesn't export any side or node sets. What should happen is that the side set and node set ids should be the same right? And there should be a set for every boundary/interface.

In the *.unv file, there are coordinates for each node. And perhaps the node ID is given as the first piece of information for each node. 

2411 denotes nodes
2412 denotes elements
2467 denotes groups (of elements or nodes)

In the elements description, the description of 2D face elements differs from the description of 1D edge elements.

In my 3x3 mesh case example, there are 16 nodes. There are 9 face elements and 12 edge elements for a total of 21 elements. There appear to be 11 numbers that describe the face elements and 10 numbers that describe the edge elements. 

A decent thread on the UNV file format: http://www.code-aster.org/forum2/viewtopic.php?id=14355

So much to learn here. Not quite sure why I seem to be struggling so much. Programmatic learning:

I'm looking at between.i. It loads a file mesh with element blocks 'left' and 'right.' Without conducting any mesh modification, no sidesets or nodesets appear when I load the _in.e file in paraview. However, when SideSetsBetweenSubdomains is called as a MeshModifier, a single sideset called in_between is created as well as a Nodeset called "Unnamed set ID: 1". So my question is: why the nodeset creation??

Full-dimensional elements have sides. But not all sides are what we consider "boundaries." Looking at the code in SideSetsBetweenSubdomains, it looks like a single side can be given multiple boundary IDs and correspondingly multiple boundary names. That seems a little peculiar to me but whatever. There are various versions of the function getBoundaryIDs, but the one I'm looking at is passed the arguments "boundary_names" and "true". True indicates that the getBoundaryIDs function needs to create ids for the boundary_names being passed because in our case we are creating a brand new boundary that doesn't have any ID yet. 


add_side 	( 	const dof_id_type  	elem,
		const unsigned short int  	side,
		const boundary_id_type  	id 
	) 	

Add side side of element number elem with boundary id id to the boundary information data structure.

std::string& libMesh::BoundaryInfo::sideset_name 	( 	boundary_id_type  	id	) 	

Returns a writable reference for setting an optional name for a sideset.


std::string & libMesh::BoundaryInfo::nodeset_name 	( 	boundary_id_type  	id	) 	

Returns a writable reference for setting an optional name for a nodeset.

The actions on boundary_info in SideSetsBetweenSubdomains are boundary.info.add_side and boundary_info.sideset_name.

Perhaps any time a boundary is created by adding sides, both a sideset and a nodeset are created. 

Hell fffiinng yea, I think I'm starting to be able to read C++ and Moose better. I managed to successfully add a nodeset name!!

Alright, trying to add multiple sidesets at the same location does not work. What I imagine happening is that initially the sides are looped over and given the first name, then the same sides are looped over again and the first name is replaced with the second name. You have to think at the geomtric level! A set of sides is a sideset. A set of nodes is a nodeset. Two elements can share the same side. That happens at the interface between blocks left and right. Similarly, I envision that when I compound meshes in Salome, the meshes are physically joined such that we have the same case where elements on different blocks share the same side at the interface. Similarly we do not have an extra domain where the Lagrange multiplier variables live. The edge elements at the interface are the sides shared by the two blocks. Cannot create something out of nothing. Perhaps it's appropriate to think that a geomtric entity can only be used/named/given-an-id once. Perhaps.

Sideset and Nodeset names when viewed in paraview should absolutely match!!! This is because their name is taken from the boundary_name, which the sideset and nodeset should share.

In dump.txt:

      master                     = (required)                  # Master side ID
      slave                      = (required)                  # Slave side ID
      subdomain                  = (required)                  # Subdomain name that is the mortar interface

# Master side ID ==> More clearly, this is the boundary ID on the master side of the mortar interface
# Slave side ID ==> More clearly, this is the boundary ID on the slave side of the mortar interface

Left side slope: 3/0.5 = 6
Right side slope: -2/0.5 = -4

Difference in slopes = 6--4 = 10
Very weird hahaha

LHS slope = 5.5/0.5 = 11
RHS slope = -4.5/0.5 = -9
Difference in slopes = 11--9 = 20

So the computer's doing exactly what it's told, although it's apparently being told something quite different from the instructions that I thought I was giving. Apparently I was specifiying the change in the gradient...wouldn't that be kind of like the laplacian?? Whatever, this isn't what I'm trying to investigate.

An additional important note: it appears that only one BC can be specified for any given variable on a boundary. This would make sense since we are in the business of solving boundary value problems.

Either nodeset_name or sideset_name can be called in order to connect the boundary IDs with the boundary names in SideSetsBetweenSubdomains. And as soon as either of those naming functions has been called, the boundary ID-name connection has been made. Then regardless of whether nodeset_name or sideset_name was used, both IntegratedBC and NodalBC can access the required respective sideset or nodeset using the boundary name -> boundaryID -> sideset or nodeset connected to that boundaryID.

It's funny, sideset_name can be called even if you didn't add a sideset. Like with AddExtraNodeset, no sideset was added (you can't find one in the mesh file), but you can call sideset_name to make the connection between boundaryIDs and boundaryNames. That's the only purpose of sideset_name and nodeset_name that I can see, is making the connection between boundary_ids and boundary_names. Almost seems redundant to have both methods. Obviously sideset_name will only added a named sideset entity in the mesh file if a sideset was actually created. 

As expected trying to implement a NeumannBC on a boundary that has no corresponding sideset does nothing. It's very important to remember then that if a boundary ID/name exists but there's not a corresponding sideset/nodeset, then MOOSE will not tell you that anything is wrong, but it will not enforce your Integrated/Nodal BC. 

Very neat conversation on an Elmer forum originating from a guy wanting to do something very similar to me (includes mention of DG, mortar, mesh interfacing, etc.)

In the conforming_two_var_out.i test, u ranges from 0 to 1 and v ranges from 0 to 0.0388393. Do the lagrange multipliers actually play a role in the dependent variable solution? lm_u ranges from -4.68841 to 2.49956 and lm_v ranges from -0.353036 to 0.127077. 

My test conclusively shows that my .unv file is not being read correctly. Specifically, I can change the mortar subdomain from 'Interface' (a group of edges on my mesh in Salome that should exist when read in by Moose) to 'Jabroni' (a totally fictional non-existent thing) and the problem computes the exact same results.

When creating libraries that may eventually be linked, The -fPIC flag enables the compilers to create position independent code, needed for shared libraries in Ubuntu on a 64 bit Intel processor. So in order to make exodus link with netcdf (I compiled netcdf before exodus), I had to make sure I configured netcdf to use CFLAGS=CXXFLAGS=CPPFLAGS=F90FLAGS=FFLAGS="-fPIC". Just using CFLAGS="-fPIC" did not do the trick. My guess would be that CPPFLAGS was the necessary addition, but I'm not going to spend the time to go check it out. The PIC in -fPIC stands for position independent code.

I believe first declaration of _all_objects (found by using my etags table) is in Warehouse.h. Here's the declaration line:

  /// All instances of objects (raw pointers)
  std::vector<T *> _all_objects;

Declaration vs definition: When you declare a variable, a function, or even a class all you are doing is saying: there is something with this name, and it has this type. Defining something means providing all of the necessary information to create that thing in its entirety. Defining a function means providing a function body; defining a class means giving all of the methods of the class and the fields. Once something is defined, that also counts as declaring it; so you can often both declare and define a function, class or variable at the same time. But you don't have to.

For example, having a declaration is often good enough for the compiler.

There are twelve tags of _dg_kernels. The declaration/definition is on line 508 of include/base/NonlinearSystem.h: 

  std::vector<DGKernelWarehouse> _dg_kernels;

On line 655 of NonlinearSystem.C in the function NonlinearSystem::addDGKernel, we have _dg_kernels[tid].addDGKernel(dg_kernel)

So here's the thing: there are three definitions of addDGKernel. There's FEProblem::addDGKernel, NonlinearSystem::addDGKernel, and DGKernelWarehouse::addDGKernel. Which definition gets called?

All the operations on the _dg_kernels variable occur in the NonlinearSystem.C file (there are 11 operations). _dg_kernels is a protected member of the NonlinearSystem class. 

Class variables and functions are both class "members." Members of a derived class can access protected members of the base class but not private members of the base class. Members who aren't in the derived or base class cannot access protected or private members of the base class. Public members can be accessed by members outside the class. 

The keyword "this" represents a pointer to the object whose member function is being executed. It is used within a class's member function to refer to the object itself.

After the declarations of Rectangle and rect, any of the public members of object rect can be accessed (in Main or in other classes) as if they were normal functions or normal variables, by simply inserting a dot (.) between object name and member name. The only members of rect that cannot be accessed from outside the class are width and height, since they have private access and they can only be referred to from within other members of that same class.


    private members of a class are accessible only from within other members of the same class (or from their "friends").
    protected members are accessible from other members of the same class (or from their "friends"), but also from members of their derived classes.
    Finally, public members are accessible from anywhere where the object is visible.

Recall that _dg_kernels is a vector. This vector contains values of type DGKernelWarehouse. So _dg_kernels is a vector of objects of type (class) DGKernelWarehouse.

The class DGKernelWarehouse has a public member function updateActiveDGKernels(Real t, Real dt). It makes sense that this is public, otherwise we couldn't execute the command:

_dg_kernels[tid].updateActiveDGKernels(t, dt);

on line 2400 of NonlinearSystem.C (there is no friendship between DGKernelWarehouse and NonlinearSystem)

Note that _dg_kernels[tid] simply has the type DGKernelWarehouse because we've accessed an index of the vector. 

void
DGKernelWarehouse::addDGKernel(MooseSharedPointer<DGKernel> & dg_kernel)
{
  _all_ptrs.push_back(dg_kernel);
  _all_objects.push_back(dg_kernel.get());
}

Where are the calls to addDGKernel? 

void
FEProblem::addDGKernel(const std::string & dg_kernel_name, const std::string & name, InputParameters parameters)
{
  parameters.set<FEProblem *>("_fe_problem") = this;
  if (_displaced_problem != NULL && parameters.get<bool>("use_displaced_mesh"))
  {
    parameters.set<SubProblem *>("_subproblem") = _displaced_problem.get();
    parameters.set<SystemBase *>("_sys") = &_displaced_problem->nlSys();
    _reinit_displaced_face = true;
  }
  else
  {
    parameters.set<SubProblem *>("_subproblem") = this;
    parameters.set<SystemBase *>("_sys") = &_nl;
  }
  _nl.addDGKernel(dg_kernel_name, name, parameters);
}

So this is from the FEProblem class and it calls the addDGKernel function of the NonlinearSystem class. As expected, the addDGKernel member of the NonlinearSystem class is public. (It had to be.)

void
AddDGKernelAction::act()
{
  _problem->addDGKernel(_type, _name, _moose_object_pars);
}

I'm guessing that this calls the addDGKernel function in the FEProblem class. 

void
NonlinearSystem::addDGKernel(std::string dg_kernel_name, const std::string & name, InputParameters parameters)
{
  for (THREAD_ID tid = 0; tid < libMesh::n_threads(); ++tid)
  {
    parameters.set<MaterialData *>("_material_data") = _fe_problem._bnd_material_data[tid];
    parameters.set<MaterialData *>("_neighbor_material_data") = _fe_problem._neighbor_material_data[tid];

    MooseSharedPointer<DGKernel> dg_kernel = MooseSharedNamespace::static_pointer_cast<DGKernel>(_factory.create(dg_kernel_name, name, parameters, tid));

    _dg_kernels[tid].addDGKernel(dg_kernel);
  }

  _doing_dg = true;
}

So recall that programming is logical and sequential. How do I think adding a DGKernel progresses at this point?:

AddDGKernelAction::act() ==> FEProblem::addDGKernel ==> NonlinearSystem::addDGKernel ==> DGKernelWarehouse::addDGKernel

There are of course 63 references to the function act(). There are also 57 definitions. All of the definitions are in the src/actions directory.

6 extra references (references that aren't simply declarations). 5 of these are in the ActionWarehouse.C. One is in the parent class Action.h

foo->bar is equivalent to (*foo).bar, i.e. it gets the member called bar from the struct that foo points to.

So foo points to an object of a class. foo->bar gets the member called bar from the class object that foo points to. 

class Action : public ConsoleStreamInterface
{
public:
  Action(InputParameters parameters);
  virtual ~Action() {}                  // empty virtual destructor for proper memory release


act is a point that points to type/class Action

What are we doing when we do act->type(); ??

What this looks like to me is an attempt to access the member function type() of the class Action. The problem is that there is no member function type() in the class Action. However in the constructor of Action we have the line   Action(InputParameters parameters);

And the class InputParameters does have a member function type that returns std::string. However, it also accepts const std::string &name, and there doesn't appear to be any passing in act->type();

Man this is a heavy dose of c++. 

      for (std::vector<Action *>::const_iterator k = _action_blocks.at(*j).begin(); k != _action_blocks.at(*j).end(); ++k)

k is a constant iterator over a vector of pointers that point to actions. That's my attempt at translating. Don't know whether it's right. 

C++ STL is the C++ Standard Template Library. 

std::vector is a sequence container that encapsulates dynamic size arrays

An interator is a pointer. You can think of an iterator as pointing to an item that is part of a larger container of items.  For instance, all containers support a function called begin, which will return an iterator pointing to the beginning of the container (the first element) and function, end, that returns an iterator corresponding to having reached the end of the container. In fact, you can access the element by "dereferencing" the iterator with a *, just as you would dereference a pointer. 

A pointer is a variable which stores the address of another variable. 

int firstvalue, secondvalue;
  int * mypointer;

  mypointer = &firstvalue;
  *mypointer = 10;


    & is the address-of operator, and can be read simply as "address of"
    * is the dereference operator, and can be read as "value pointed to by"

        Action * act = *k;

The above line means that the Action pointed to by act is equal to the Action pointed to by the const_iterator k

I'm conducting a sleuth hunt. There are four places where type() is defined: MaterialProperty.h, RestartableData.h, ArbitraryQuadrature.C, and InputParameters.C

global -v --result=grep --color=always --path-style=shorter --from-here=149:src/actions/ActionWarehouse.C type
include/materials/MaterialProperty.h:216:MaterialProperty<T>::type ()
include/restart/RestartableData.h:142:RestartableData<T>::type ()
src/utils/ArbitraryQuadrature.C:28:ArbitraryQuadrature::type() const
src/utils/InputParameters.C:444:InputParameters::type(const std::string &name)
4 objects located (using '/home/lindsayad/projects/moose/framework/GTAGS').

Global found 4 definitions at Mon Oct  5 16:59:56

Type Action does not have a "definition" of a member type() as determined by ggtags, but a quick search in the Action.h file reveals:

  const std::string & type() const { return _action_type; }

ggtags likely considers this to be a declaration as opposed to a definition, and unfortunately there are 783 references to type(). However, we know that the member type() either has to be defined (in the real sense, not the ggtags interpretation), in the Action class or in one of the parent classes of Action. We have to exercise our knowledge!

Action inherits from ConsoleStreamInterface.

act->type is executed in ActionWarehouse.C

ActionWarehouse inherits from Warehouse. If we assume that Action and ActionWarehouse don't share any inheritance, then we could have deduced that the member function type() of class Action had to be public (which it is). 

All this knowledge gathering stems from me trying to determine when AddDGKernelAction::act() gets called. It has to get called in 

void
ActionWarehouse::executeActionsWithAction(const std::string & task)
{
  // Set the current task name
  _current_task = task;

  for (ActionIterator act_iter = actionBlocksWithActionBegin(task);
       act_iter != actionBlocksWithActionEnd(task);
       ++act_iter)
  {
    if (_show_actions)
    {
      _console << "[DBG][ACT] "
               << "TASK (" << COLOR_YELLOW << std::setw (24) << task << COLOR_DEFAULT << ") "
               << "TYPE (" << COLOR_YELLOW << std::setw (32) << (*act_iter)->type() << COLOR_DEFAULT << ") "
               << "NAME (" << COLOR_YELLOW << std::setw (16) << (*act_iter)->getShortName() << COLOR_DEFAULT << ") ";

      (*act_iter)->act();
    }
    else
      (*act_iter)->act();
  }
}

I'm looking at actionBlocksWithActionBegin(task) ==> 

ActionIterator
ActionWarehouse::actionBlocksWithActionBegin(const std::string & task)
{
  return _action_blocks[task].begin();
}

  /// Pointers to the actual parsed input file blocks
  std::map<std::string, std::vector<Action *> > _action_blocks;

So looks like we've gone all the way back to the parsing of the input file (which is one of the things I wanted to do!). I knew that the problem was translated from the input file into the Moose executable and problem solving using Actions. (Actions are input blocks right? I mean yes they bloody are. When I created new actions, I created new input blocks, with proper input block syntax specified. Yes input file syntax is done in ZapdosApp::associateSyntax, and one of the arguments we pass is action_factory.)

executeActionsWithAction is referenced in the following places:

include/actions/ActionWarehouse.h:119:  void executeActionsWithAction(const std::string & name);
src/actions/ActionWarehouse.C:308:    executeActionsWithAction(task);
src/base/MooseApp.C:457:  _action_warehouse.executeActionsWithAction("set_global_params");
src/base/MooseApp.C:458:  _action_warehouse.executeActionsWithAction("setup_mesh");
src/base/MooseApp.C:459:  _action_warehouse.executeActionsWithAction("prepare_mesh");
src/base/MooseApp.C:460:  _action_warehouse.executeActionsWithAction("add_mesh_modifier");
src/base/MooseApp.C:461:  _action_warehouse.executeActionsWithAction("execute_mesh_modifiers");
src/base/MooseApp.C:462:  _action_warehouse.executeActionsWithAction("uniform_refine_mesh");
src/base/MooseApp.C:463:  _action_warehouse.executeActionsWithAction("setup_mesh_complete");

Something that's interesting to note is that in:

ActionWarehouse::executeAllActions()
{
  if (_show_actions)
  {
    _console << "[DBG][ACT] Action Dependency Sets:\n";
    printActionDependencySets();

    _console << "\n[DBG][ACT] Executing actions:" << std::endl;
  }

  for (std::vector<std::string>::iterator it = _ordered_names.begin(); it != _ordered_names.end(); ++it)
  {
    std::string task = *it;
    executeActionsWithAction(task);
  }
}

the executeActionsWithAction member function of ActionWarehouse is called without any '.' or '->' or '::'. This is because there is no ambiguity about what namespace we are using because we are within a member function of ActionWarehouse calling a fellow member function of ActionWarehouse. 

It looks like the actions of adding kernels is conducted during mesh preparation, and this process is initiated from lines 457-463 of MooseApp.C, which is within the meshOnly member function of MooseApp

meshOnly is executed only if user specifies --mesh-only when running his executable from the command line. Thus the important call of executeActionsWithAction happens in executeAllActions() which is called from MooseApp::runInputFile(), which is called from MooseApp::run(), which is called from these lines in the main.C file of Zapdos:

  // This creates dynamic memory that we're responsible for deleting
  MooseApp * app = AppFactory::createApp("ZapdosApp", argc, argv);

  // Execute the application
  app->run();

Wooooo!!!!!!!!!! We traced it all the way back to the beginning using the power of the ggtags!!!!!! Good day :-) The power of C++ is being channelled into my mind!!!!!!!!

There are three places where computeResidual gets called in ComputeResidualThread: in onElement (kernels), onBoundary (integrated BCs), and onInternalSide (DGKernels)

In ThreadedElementLoopBase we have the calls:

      onElement(elem);

      for (unsigned int side=0; side<elem->n_sides(); side++)
      {
        std::vector<BoundaryID> boundary_ids = _mesh.boundaryIDs(elem, side);

        if (boundary_ids.size() > 0)
          for (std::vector<BoundaryID>::iterator it = boundary_ids.begin(); it != boundary_ids.end(); ++it)
            onBoundary(elem, side, *it);

        if (elem->neighbor(side) != NULL)
          onInternalSide(elem, side);
      } // sides
      postElement(elem);

Need to investigate how ComputeResidualThread::onElement might get called here

Or need to say if there are other places where computeResidual gets called

There are 14 definitions of onElement as defined by ggtags:

include/base/ThreadedElementLoopBase.h:199:ThreadedElementLoopBase<RangeType>::onElement(const Elem * /*elem*/)
src/base/CacheChangedListsThread.C:34:CacheChangedListsThread::onElement(const Elem *elem)
src/base/ComputeDampingThread.C:44:ComputeDampingThread::onElement(const Elem *elem)
src/base/ComputeDiracThread.C:71:ComputeDiracThread::onElement(const Elem * elem)
src/base/ComputeElemAuxVarsThread.C:75:ComputeElemAuxVarsThread::onElement(const Elem * elem)
src/base/ComputeIndicatorThread.C:83:ComputeIndicatorThread::onElement(const Elem *elem)
src/base/ComputeJacobianThread.C:148:ComputeJacobianThread::onElement(const Elem *elem)
src/base/ComputeMarkerThread.C:76:ComputeMarkerThread::onElement(const Elem *elem)
src/base/ComputeMaterialsObjectThread.C:78:ComputeMaterialsObjectThread::onElement(const Elem *elem)
src/base/ComputeResidualThread.C:99:ComputeResidualThread::onElement(const Elem *elem)
src/base/ComputeUserObjectsThread.C:164:ComputeUserObjectsThread::onElement(const Elem * elem)
src/base/FlagElementsThread.C:57:FlagElementsThread::onElement(const Elem *elem)
src/base/ProjectMaterialProperties.C:75:ProjectMaterialProperties::onElement(const Elem *elem)
src/base/UpdateErrorVectorsThread.C:57:UpdateErrorVectorsThread::onElement(const Elem *elem)

kernel->computeResidual() in NonlinearSystem::computeResdiaulInternal(Moose::KernelType type) which is called from:

void
NonlinearSystem::computeResidual(NumericVector<Number> & residual, Moose::KernelType type)

computeResidual is called in several places as we have seen. 

Let's understand polymorphism. Looking at our polymorphism example, ppoly1->area()

ppoly is defined as a pointer that points to an object of type Polygon, that in this case is assigned to the address of the the object Rectangle rect (this assignment is fine because rect is a Rectangle but it is also a Polygon), so ppoly1->area() accesses the area() member function of Rectangle rect. Because ppoly is defined as a pointer that points to an object of type Polygon, only members inherited from Polygon can be accessed using -> . Member functions defined in a base class but taggged with virtual can be re-defined in a derived class, and then those derived class function members can be accessed through a pointer to the base class. However, if the virtual tag was not given in the base class, then a member function with the same name in a derived class would be unaccessible through a pointer to the base class. 

computeResidual calls:

src/base/ComputeDiracThread.C:113:          dirac_kernel->computeResidual(); ==> DiracKernel::computeResidual()
src/base/ComputeResidualThread.C:114:    (*it)->computeResidual(); ==> it points to type KernelBase. ==> KernelBase::computeResidual()
src/base/ComputeResidualThread.C:144:        bc->computeResidual(); ==> IntegratedBC::computeResidual
src/base/ComputeResidualThread.C:180:        dg->computeResidual(); ==> DGKernel::computeResidual
src/base/FEProblem.C:3281:  computeResidual(sys, u, residual); ==> FEProblem::computeResidual
src/base/FEProblem.C:3330:  _nl.computeResidual(residual, type); ==> _nl is of type NonlinearSystem, thus this calls ==> NonlinearSystem::computeResidual
src/base/FEProblem.C:3386:    computeResidual(sys, soln, *sys.rhs); ==> FEProblem::computeResidual
src/base/NonlinearSystem.C:86:    p->computeResidual(sys, soln, residual); ==> FEProblem::computeResidual
src/base/NonlinearSystem.C:233:    _fe_problem.computeResidual(_sys, *_current_solution, *_sys.rhs); ==> FEProblem::computeResidual
src/base/NonlinearSystem.C:866:        nc->computeResidual(residual); ==> nc points to a NodalConstraint ==> NodalConstratin::computeResidual
src/base/NonlinearSystem.C:1073:                nfc->computeResidual(); ==> NodeFaceConstraint::computeResidual
src/base/NonlinearSystem.C:1159:          ffc->computeResidual(); ==> FaceFaceConstraint:computeResidual
src/base/NonlinearSystem.C:1228:        kernel->computeResidual(); ==> ScalarKernel::computeResidual()
src/base/NonlinearSystem.C:1309:            bc->computeResidual(residual); ==> NodalBC::computeResidual()
src/bcs/NodalNormalBC.C:49:  NodalBC::computeResidual(residual);

computeResidual complete definitions (as defined by ggtags):

src/base/FEProblem.C:3263:FEProblem::computeResidual(NonlinearImplicitSystem &/*sys*/, const NumericVector<Number> & soln, NumericVector<Number> & residual)
src/base/NonlinearSystem.C:702:NonlinearSystem::computeResidual(NumericVector<Number> & residual, Moose::KernelType type)
src/bcs/IntegratedBC.C:102:IntegratedBC::computeResidual()
src/bcs/NodalBC.C:73:NodalBC::computeResidual(NumericVector<Number> & residual)
src/bcs/NodalNormalBC.C:45:NodalNormalBC::computeResidual(NumericVector<Number> & residual)
src/constraints/FaceFaceConstraint.C:122:FaceFaceConstraint::computeResidual()
src/constraints/NodalConstraint.C:48:NodalConstraint::computeResidual(NumericVector<Number> & residual)
src/constraints/NodeFaceConstraint.C:108:NodeFaceConstraint::computeResidual()
src/dgkernels/DGKernel.C:130:DGKernel::computeResidual()
src/dirackernels/DiracKernel.C:81:DiracKernel::computeResidual()
src/kernels/EigenKernel.C:71:EigenKernel::computeResidual()
src/kernels/Kernel.C:47:Kernel::computeResidual()
src/kernels/KernelGrad.C:37:KernelGrad::computeResidual()
src/kernels/KernelValue.C:37:KernelValue::computeResidual()
src/kernels/NodalEqualValueConstraint.C:46:NodalEqualValueConstraint::computeResidual()
src/kernels/ODEKernel.C:40:ODEKernel::computeResidual()
src/kernels/TimeKernel.C:34:TimeKernel::computeResidual()

Kernel is a direct child of KernelBase

I want to understand this function:

void
ComputeResidualThread::onElement(const Elem *elem)
{
  _fe_problem.prepare(elem, _tid);
  _fe_problem.reinitElem(elem, _tid);
  _fe_problem.reinitMaterials(_subdomain, _tid);

  const std::vector<KernelBase *> * kernels = NULL;
  switch (_kernel_type)
  // _kernel type is obviously a member variable of ComputeResidualThread and it is of type Moose::KernelType
  // _kernel_type is initialized in the constructor
  {
  case Moose::KT_ALL: kernels = & _sys.getKernelWarehouse(_tid).active(); break;
  case Moose::KT_TIME: kernels = & _sys.getKernelWarehouse(_tid).activeTime(); break;
  case Moose::KT_NONTIME: kernels = & _sys.getKernelWarehouse(_tid).activeNonTime(); break;
  }
  for (std::vector<KernelBase *>::const_iterator it = kernels->begin(); it != kernels->end(); ++it)
  {
    (*it)->computeResidual();
  }

  _fe_problem.swapBackMaterials(_tid);
}

The constructor tells us how to construct the class. (How about that ?!)

As an example:

ComputeResidualThread::ComputeResidualThread(FEProblem & fe_problem, NonlinearSystem & sys, Moose::KernelType type) :
    ThreadedElementLoop<ConstElemRange>(fe_problem, sys),
    _sys(sys),
    _kernel_type(type),
    _num_cached(0)
{
}

So when an object of type ComputeResidualThread is declared in another piece of code, it must be initialized with three arguments matching: (FEProblem & fe_problem, NonlinearSystem & sys, Moose::KernelType type)

Now ComputeResidualThread has three data members: _sys, _kernel_type, and _num_cached. It also publicly inherits the members of ThreadedElementLoop<ConstElemRange>. The constructor tells us that _sys should be set equal to sys passed by the user, _kernel_type should be set equal to tyoe passed by the user, and _num_cached should be set equal to zero (not passed by the user). Finally the members of ThreadedElementLoop can be created by passing the user supplied variables fe_problem and sys. 

Now I recognize that in order to be able to use _kernel_type in ComputeResidualThread::onElement, an object of type ComputeResidualThread must have been created prior to that such that _kernel_type has been initialized. 

And in fact, there is one place where an ComputeResdiaul object is created: in NonlinearSystem::computeResidualInternal(Moose::KernelType type) :

    ComputeResidualThread cr(_fe_problem, *this, type);

NonlinearSystem::computeResidualInternal is called from NonlinearSystem::computeResidual

_nl must be a data member of FEProblem. Sure enough on line 904 of FEProblem.h, I see the protected variable declaration:

NonlinearSystem & _nl;

Here's where _nl is initialized in the constructor of FEProblem:

     _nl(getParam<bool>("use_nonlinear") ? *(new NonlinearSystem(*this, name_sys("nl", _n))) : *(new EigenSystem(*this, name_sys("nl", _n)))),

The keyword this represents a pointer to the object whose member function is being executed. It is used within a class's member function to refer to the object itself. The only object that the FEProblem::FEProblem constructor reads in is const InputParameters & parameters. 

I believe that * in the _nl case is dereferencing. 

What does the initialization statement actually mean? It means this:

NonlinearSystem & _nl = getParam<bool>("use_nonlinear") ? *(new NonlinearSystem(*this, name_sys("nl", _n))) : *(new EigenSystem(*this, name_sys("nl", _n)))

Dynamic memory is allocated using operator new. new is followed by a data type specifier and, if a sequence of more than one element is required, the number of these within brackets []. It returns a pointer to the beginning of the new block of memory allocated. Its syntax is:

pointer = new type
pointer = new type [number_of_elements]

C++ references allow you to create a second name for the a variable that you can use to read or modify the original data stored in that variable. While this may not sound appealing at first, what this means is that when you declare a reference and assign it a variable, it will allow you to treat the reference exactly as though it were the original variable for the purpose of accessing and modifying the value of the original variable--even if the second name (the reference) is located within a different scope. This means, for instance, that if you make your function arguments references, and you will effectively have a way to change the original data passed into the function. This is quite different from how C++ normally works, where you have arguments to a function copied into new variables. It also allows you to dramatically reduce the amount of copying that takes place behind the scenes, both with functions and in other areas of C++, like catch clauses. 

So _nl is a reference! 

Ampersand on the LHS of an assignment ==> creating a reference
Ampersand on the RHS of an assignment ==> creating a pointer

Recall the NonlinearSystem constructor:

NonlinearSystem::NonlinearSystem(FEProblem & fe_problem, const std::string & name)

More assignments:

FEProblem & fe_problem = *this
const std::string & name = name_sys("nl", _n)

Alright so 'this' in this context is the pointer to the FEProblem object.

So when we construct a FEProblem object, we create a new NonlinearSystem. This NonlinearSystem and FEProblem are closely coupled because when we create the new NonlinearSystem, we pass it the FEProblem object that we're concurrently constructing. name_sys is a simple function that returns type std::string. I don't know whether it has to be included in the FEProblem.C file in order for the FEProblem contsructor to call it. It either has to be in that source file or in another included file. (It has to be somewhere!!)

The fe_problem might be created on line 338 of MooseApp.C within the runInputFile member function:

    MooseSharedPointer<FEProblem> fe_problem= _action_warehouse.problem();

_action_warehouse is a data member of MooseApp. It's initialized in the following way:

    _action_warehouse(*this, _syntax, _action_factory),

'this' is a pointer to a MooseApp object

ActionWarehouse::ActionWarehouse(MooseApp & app, Syntax & syntax, ActionFactory & factory)

ActionWarehouse (or one of its parents) must have a member function problem()

Here it is:

  MooseSharedPointer<FEProblem> & problem() { return _problem; }

This returns a reference to a MooseSharePointer<FEProblem> called _problem

I'm a little perplexed by the ActionWarehouse class. It has a protected data member:

MooseSharedPointer<FEProblem> _problem

Does that data member get initialized by the constructor?? Ah I see. It's not illegal to create data members that aren't initialized by constructors. It's just that if we try to do something with those declared variables before we define them we will get an undetermined result. 

Forward declaration

A declaration of the following form
class-key attr identifier ; 		

Declares a class type which will be defined later in this scope. Until the definition appears, this class name has incomplete type. This allows classes that refer to each other: 

class Vector; // forward declaration
class Matrix {
    // ...
    friend Vector operator*(const Matrix&, const Vector&);
};
class Vector {
    // ...
    friend Vector operator*(const Matrix&, const Vector&);
};

In ScalarKernel.h we have this:

  virtual void computeResidual() = 0;

There are children of the class ScalarKernel that define computeResidual and thus would override the virtual computeResidual() in ScalarKernel. On line 1225, I think it's conceivable that *it could dereference to children of ScalarKernels, and thus because of the use of the virtual computeResidual, those children's computeResidual function definitions could get called. The exact same reasoning is true for KernelBase. We have this line in KernelBase.h:

  virtual void computeResidual() = 0;

In fact of the all the computeResidual declarations in header files, only ScalarKernel and KernelBase have the = 0 assignments, such that the system is completely defined. This coding is beautiful.

Departing briefly from the beautiful moose framework, I am building my AVS talk. 

I'm trying to compare energy and LFA formulations. In order to do that, I need to make sure I'm using corresponding transport and rate coefficients between the two cases. I'm going to use argon as my gas. I'm only going to consider elastic and ionization reactions. In order to make my energy formulation more closely aligned with physical reality, I need to examine the following parameters:

_Eiz_en ==> 15.76 eV (Lieberman)
_rate_coeff_ion_en ==> 5e-14 m^3/s (Lieberman)
_muem ==> TBD
_diffem ==> TBD
_muip ==> TBD
_diffip ==> TBD
_rate_coeff_elastic ==> Already correct (Lieberman)
Potential ==> -2.5 kV (Go experiment at atmosphere with argon)
Ballast resistor ==> 8.1 kOhm (Go experiment at atmosphere with argon)
Gap distance ==> 1-2 mm (Go experiment at atmosphere with argon)

Keep in mind that some of these params may have to be adjusted for the simulation (I have to be sure I can get convergence!). Whatever params I adjust though should be params that can also be adjusted for the LFA simulation. There may even be a physical reason to say reduce the applied potential or increase/decrease the area of the plasma such that it puts less stress on the numerical system. If a measure of stress on the system is the concentration of ions at the cathode, then there are several ways to decrease that stress:

Decrease applied potential
Increase ion mobility 
Increase ballast resistance
Increase electrode/plasma area (==> this could derive a bit from what Go was saying, if a certain increase in curent is required and the potential is constant, then the diameter of the plasma must increase ==> Current = current density (should be constant?) * area (variable?))

I believe that in order for thunderbird to match a name to a email address, I must have received or sent an email from/to that person while I've had the thunderbird application installed on the particular computer. That's fair.

Again I note that bolos reproduces bolsig results. Figure 3.16 on pg. 80 of Lieberman looks kind of like a big sack of horse-poo compared to the results I predict with bolos or bolsig. Perhaps this is because of the 2-term approximation used in bolsig and currently in my bolos calculations. But it seems like Lieberman predicts much higher rates of ionization than bolos/bolsig does. What to do?

See here's a conundrum. The current functional form I've been using for my source terms is alpha s porportional to exp(-A/|Field|) or Kiz is proportional to exp(-B/|Te|). Neither of those functional forms are actually physically correct, e.g. both those terms continue to grow respectively with the field and the electron temperature. They most certainly do not plateau at some threshold value. I don't want to take the time to try and navigate any possible additional complexity introduced by lookup tables right now. There's also the pain in the ass realization that if I alter the functional forms of alpha and Kiz, I'm going to have to implement new Jacobians and new residuals.

For a p=5 polynomial fit of EField vs. alpha, without a penalty for negative model values (with initial guess of 1.e-14 for all coefficients): (a0,a1....,a5)
[  1.00000000e-14,  -7.33794821e-03,   1.02893016e-08,
        -1.50362990e-15,   1.09634198e-22,  -3.16558448e-30]

With a penalty for negative values:
[  1.00000000e-14,  -7.23069891e-03,   9.41410909e-09,
        -1.18445467e-15,   6.90018879e-23,  -1.43863034e-30]

Now I want to try fitting A*T^B*exp(-C/T)

Alright, I got a frieking awesome curve fit with the Lieberman function. Fit values for the electric field vs alpha:

[  1.43171672e-01,   9.05925536e-01,   3.04958892e+06]

Using the stupid function. Fit values for the electric field vs alpha:

array([  485001.06154102,  8073212.48740293])

Curve fit for mean_energy vs. kArIz, Lieberman function:
array([  1.43878529e-11,  -2.70610234e-01,   7.64727794e+01])

Curve fit for mean_energy vs. kArIz, stupid function:
array([  6.24642728e-12,   7.43060838e+01])

The mean_energy curve fit is not nearly as good as the EField curve fit. And the exponential factor of 76 Volts makes absolutely no sense. It could be because we're not assuming a Maxwellian distribution??

With a mesh size of 100, solve failed at 1.29159e-08 seconds because of oscillations in the ions. With 200 elements the result is even worse. Oscillations immediately. Solve fails after 3 steps at 3.64e-09 seconds. 

With my sweet spot of 4000 elements, still see some spectacular oscillations. Solve fails at 4.54e-09 seconds. 

I went back to 100 elements, and decreased the voltage by a factor of 100. This time the onset of oscillations in the ions was a little delayed but they did indeed appear, and the solve failed at 2.25989e-08 sconds. Going back to 4000 elements, still with the decreased voltage: oscillations witnessed and solve fails at 1.08299e-08 seconds. 

The reason for the above failures is that I had a negative diffusion coefficient for the ions: dope!! With that fixed, the solve appears to start chugging along fine until it reaches around 1e-6 seconds (when the potential is rising at a rapid rate towards its max value), and then I get a terrible MUMPS error: 

[3]PETSC ERROR: [0]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[0]PETSC ERROR: Error in external library
[0]PETSC ERROR: Error reported by MUMPS in numerical factorization phase: INFO(1)=-1, INFO(2)=1

[0]PETSC ERROR: See http://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[0]PETSC ERROR: Petsc Release Version 3.6.0, Jun, 09, 2015 
[0]PETSC ERROR: ./zapdos-opt on a arch-linux2-c-opt named lindsayad-OptiPlex-990 by lindsayad Mon Oct 12 16:05:03 2015
[0]PETSC ERROR: Configure options --prefix=/opt/moose/petsc/openmpi_petsc-3.6.0/gcc-opt --download-hypre=1 --with-ssl=0 --with-debugging=no --with-pic=1 --with-shared-libraries=1 --with-cc=mpicc --with-cxx=mpicxx --with-fc=mpif90 --download-fblaslapack=1 --download-metis=1 --download-parmetis=1 --download-superlu_dist=1 --download-scalapack=1 --download-mumps=1 CC=mpicc CXX=mpicxx FC=mpif90 F77=mpif77 F90=mpif90 CFLAGS="-fPIC -fopenmp" CXXFLAGS="-fPIC -fopenmp" FFLAGS="-fPIC -fopenmp" FCFLAGS="-fPIC -fopenmp" F90FLAGS="-fPIC -fopenmp" F77FLAGS="-fPIC -fopenmp" PETSC_DIR=/home/lindsayad/projects/src/petsc-3.6.0


My translation: the problem started getting very hard.

With the potential decreased by a factor of 10, we appear to be below the ionization threshold.

Alright potential halved from experimental value to 1.25e3. Then we are above the ionization threshold, but the solve still fails with the MUMPS error, this time at 8.53805e-06 seconds (so it made it a bit farther this time.)

After increasing the ballast resistance by a factor of two, absolutely nothing changed. Well that's not true. Although the time at which the simulation failed didn't change, the residuals did change. An important thing to note: the very previous time step, the solve converged in just 6 nonlinear iterations and reached a final residual of 1e-10. 

By moving just a little farther in the time domain (went to a uniprocessor solve without MUMPS), e.g. solve failed at 8.67973e-06 seconds, I think I can see why the MUMPS simulation was failing. Looks like we're starting to get steep gradients at the boundary that may be unresolved by the mesh. Good to see the potential at the left bound starting to decrease. I think that means that our applied potential is not too large if we're able to simulate out a point where the potential starts decreasing. 

Yea, I would say I've come quite a ways in being able to diagnose, identify, and rectify problems in my simulation. Less than an hour, I solved a brand new implementation of my DC LFA problem. Woooo!!!!!!!!!!!!!!!!!!!!!!!!!! Alive time = 28.6948 seconds. Active time = 28.4932 seconds. 

Not looking good. Mean energy simulation dies at 2.49269e-07 seconds with no obvious problems in the solutions. Everything looks nice and smooth. Thus I think the problem must be the transient I'm introducing in the boundary condition.

After changing 1/tau to 1e5, the simulation now fails at 2.02422e-06 seconds. The potential reaches -250 V. I believe it was around -350 when using 1/tau = 1e6. The solutions still look pretty and smooth. 

With potential scaling changed to 1e0 (initial value 1e-5), the solve fails at 1.2981e-06 seconds.
With potential scaling changed to 1e-1 (initial value 1e-5), the solve fails at 1.2981e-06 seconds.
With potential scaling changed to 1e-2 (initial value 1e-5), the solve fails at 1.2981e-06 seconds.
With potential scaling changed to 1e-3 (initial value 1e-5), the solve fails at 1.2981e-06 seconds.
With potential scaling changed to 1e-4 (initial value 1e-5), the solve fails at 2.02298e-06 seconds. (just a tiny bit worse than when scaling set to 1e5)

With absolute tolerance set to 1e-2, problem failed at 2.02924e-06 seconds. A little better.

mean_en scaling at 1e-23, solve fails at 1.22402-07 seconds (a_tol = 1e-1, tau = 1e-6)
mean_en scaling at 1e-20, solve fails at 1.22402-07 seconds (a_tol = 1e-1, tau = 1e-6)

The ability to solve and the result of the solve is very much dependent on the voltage rise time. For the lfa formulation, I could not get a converged solution for tau = 1e-3 & 1e-4 seconds, but I can for 1e-6 seconds. For the mean_energy formulation, I could not get a converged solution for tau = 1e-6 or 1e-5 seconds, but I got a converged solution for tau = 1e-3 seconds. What appeared to help the energy form was giving the charged species enough time to form a significant enough current such that the voltage at the left boundary never went too high. With respect to the lfa form, if I wait too long such that all the electrons and ions disappear from the domain before I apply the potential, then the problem won't converge.

I was also able to get convergence with lfa for tau = 1e-5 seconds. There appears to be no difference in the results between the 1e-6 and 1e-5 cases. 

I'm unable to get convergence using a ballast resistance of 1e6, and a rise time of 1e-5 seconds (voltage of 1.25e3, 600, 300, or 150 V) with the electron energy formulation.

It simply appears that it's way easier to create ionization using my energy functional formulation than it is using my lfa functional formulation. I don't quite know why that is. 

There are a couple of things that are different in my ionization source term between lfa and energy: lfa uses a coefficient that is a function of the electric field and multiplies the electron flux. Energy uses a coefficient that is a function of the electron energy and multiplies the electron density. 

Got quite a few options for trying to fit alpha vs mean_energy:

Letting all three parameters of Liberman's be variable:
array([  7.00485613e+07,  -3.54236666e-02,   5.31700097e+01])

Setting c = 15.76:
array([ 42.04011787,   4.588541  ])

Setting b = 1, c = 15.76 (looks terrible):
array([ 78868.24191509])

If instead of deleting the elements in alpha that are less than a certain value (1e-15 in this case), I set those elements equal to zero, the heres the three parameter fit for the Lieberman function:
array([  1.52165930e+08,  -2.87277596e-01,   5.51972192e+01])

Fit virtually doesn't change, and I still see an overshoot of the data in the 6-7 eV range.

While I was revamping my code to allow for a source flux energy formulation, I realized that my electron energy kernel was wrong: I didn't have energy being lost per ionization collision: in fact I was actually gaining energy from ionization collisions! So hopefully I fixed that.

With the revamped code, the solve fails at 7.93437e-07 seconds which is much better performance relative to tau (1e-06). Reducing the rel_tol actually hurt the solve: solve failed at 7.03832e-07 seconds. Returning rel_tol to default and changin abs_tol from 1e-1 to 1e1, the solve reached 8.85438e-07 seconds.

From the Comsol Plasma Module manual, recall thaat the Electron energy can change on scales less than a ns. 

I got the energy formulation to solve with a rise time of 1e-6 seconds. The key was simply to decrease dtmin. (Use your knowledge of the physical time scales!!! That's where being a physicist/engineer is of greatest benefit! Knowing the physics! (Time & length scales. Dependent variable scales also)). The shape of the 1e-3 and 1e-6 rise time simulations are exactly the same. And quantitatively, they are also quite similar. This would lead me to believe that the dominant path for energy loss is through elastic collisions. This would also be supported by the fact that I was able to solve with the 1e-3 rise time a problem where I had actually configured my residuals such that ionziation collisions would actually create energy!

Zapdos active time = 1063.31 seconds ==> 17.7 minutes. Not bad I would say. (using all 4 processors)

Went to the flux formulation of the energy formulation ==> Active time = 593.726 seconds = less than 10 minutes. Took 603 time steps as opposed to 1272 time steps in the case of the rate coefficient formulation of the energy formulation. I guess it is true that townsend in DC discharges is more stable than rate coefficients!!

For elastic collision rate fit:
array([  1.60638169e-13,   3.17917979e-01,   4.66301096e+00])

Ran with variable elastic collisions and the peak density actually increased :-( Zapdos active time = 575.026 seconds < 10 minutes (Had to change the absolute tolerance because it was stalling (diverged line searches after great initial residual reduction) at a few percent over 1e-5) The reason it was stalling at a slightly higher value is likely because the peak densities were a few percent higher. With the absolute tolerance change, the number of steps went from many thousands to 505.

Better fit for mean_en vs. kArIz:     y = p[0]*x**p[1]*exp(p[2]*x**p[3])

[  9.61505373e-15   1.56694111e-01  -3.62336868e+03  -3.39520538e+00]

If I can't get a good model fit...why not just use the raw data?!

There are Standard Stream Objects for Console I/O: (cout, cin, cerr, clog, etc.) A 'stream' is internally nothing but a series of characters.

std::cout - Regular output (console output)
std::cerr - Error output (console error)
std::clog - Nobody cares (console log)

When writing error messages, use cerr rather than cout. In simple examples, the two appear to be the same. However, they behave differently when you use Unix redirection operators when you run your program. In particular, if you redirect output to a file, error messages printed to cerr will still appear on the user's terminal whereas error messages printed to cout will be mixed into the output file. 

So running the interpolation problem with Newton...after about a half hour we were at time = 7.69011e-07 seconds after 1141 time steps. 

Very peculiarly, when I tried running two different zapdos simulations, each one on two cores, my process scheduler scheduled the sapdos simulations to both run on the same two cores! So two cores were just sitting there doing nothing!

As might be expected from the above passage, solving the same case as argon_energy_mumps_tau_1e-6_townsend_variable_elastic_coeff took about four times as long as the gold run. Not surprising since I was running on half the processors and theoretically it was only being executed half the time (two processes running on the two processors). Number of time steps were essentially the same. 

With jacobian_estimation (and residual given by linear interpolation, so jacob and residual not the same):

Time Step 100, time = 7.42153e-07
                dt = 4.92521e-11
Time Step 200, time = 7.4892e-07
                dt = 9.47565e-11
Time Step 300, time = 7.53893e-07
                dt = 6.07676e-11
Time Step 400, time = 7.57823e-07
                dt = 3.89705e-11
Time Step 500, time = 7.64239e-07
                dt = 5.45626e-11
Time Step 600, time = 7.67041e-07
                dt = 2.82938e-12
Time Step 875, time = 7.68072e-07
                dt = 4.98006e-12

Without jacobian_estimation:

Time Step 100, time = 2.94026e-07
                dt = 2.30869e-09
Time Step 200, time = 3.55389e-07
                dt = 5.92228e-10
Time Step 300, time = 3.82268e-07
                dt = 3.79798e-10
Time Step 600, time = 4.64467e-07
                dt = 3.00513e-10
Time Step 800, time = 5.15558e-07
                dt = 2.14569e-10

So yes it looks much worse without the jacobian_estimation

With jacob_estimation and residual the same
Time Step 100, time = 8.34043e-07
                dt = 7.2944e-11
Time Step 200, time = 8.38448e-07
                dt = 3.48495e-11
Time Step 300, time = 8.40077e-07
                dt = 6.38499e-12
Time Step 400, time = 8.59315e-07
                dt = 2.98505e-09
Time Step 500, time = 0.0457816
                dt = 0.00763011

So as expected the problem solves better when the residual and jacobian match. Who would have guessed?! The problem with that match is that my residuals don't define the right problem! And when I do define the right problem with my residuals, I can't define a matching Jacobian!!

I tried defining a matching Jacobian my doing second order differencing mean_energy vs alpha. I am using a linear interpolation for alpha in the residuals, and a linear interpolation of d_alpha_d_mean_en in the jacobians. However, Andy Wilkins suggested that in his experience linear interpolations in conjuction with implicit solves can lead to terrible convergence. I am in fact seeing terrible convergence. He gave me a reference for cubic splines. My only question then is what to do for the derivatives.

What are the coefficients that are variable? a_k, b_k, c_k, K

0,1,2 3,4,5 6,7,8 8,10,11
12,13,14

So when I run through the debugger, I get the error: Solving for an empty SplineInterpolation.

This could be the problem that's causing MPI to abort immediately. Nope. It was because of getEnv.

A get function/method is defined in the Parameters class in files included from libmesh. It's that inheritance.

When I tried using set in DGInterface with _boundary_id, I got this warning:

/home/lindsayad/moose/framework/src/dgkernels/DGInterface.C:26:42: warning: overflow in implicit constant conversion [-Woverflow]
   params.set<BoundaryID>("_boundary_id") = 78910;

  /**
   * Inserts a new Parameter into the object but does not return
   * a writable reference.  The value of the newly inserted
   * parameter may not be valid.
   */
  template <typename T>
  void insert (const std::string&);

The Elem class (from libmesh) has a function level:

  /**
   * @returns the refinement level of the current element.  If the
   * element's parent is \p NULL then by convention it is at
   * level 0, otherwise it is simply at one level greater than
   * its parent.
   */
  unsigned int level () const;

And then elem inherits members of dof_object. dof_object has a member function id ():

  /**
   * \returns the \p id for this \p DofObject
   */
  dof_id_type id () const;

Still just kind of working and navigating through the code here. 

Should I think about everyone or just think about myself?

I feel like my changes should just be limited to DGKernel parts of the framework, and even then the changes should be as minimal as possible.

I think that my DGKernel should mimic an IntegratedBC as much as possible.

It's clear that I don't know what combining CG and DG in MOOSE does.

Current task: figure out what's going on with EArray vs. alpha.

Nothing wrong with EArray vs. alpha. Fit is still perfection incarnate.

A pure CG problem with MONOMIAL basis functions will not converge; at least not when I was twiddling around with the 2d_diffusion_dg_test case. DGFunctionDiffusionDirichletBC contains the necessary DG residuals from diffusion. This BC must contain those contributions because DGDiffusion is only executed on internal sides; thus to be complete, those residual contributions must be added to the boundary condition. Then the epsilon and sigma terms are added. These almost exactly analagous to the internal epsilon and sigma terms, except u_neighbor is modified to be equal to the desired boundary value (e.g. the value of our boundary condition). Similarly, since there is no test function on the other side of the boundary, {test} = test, [test]=test, {normals*grad_test} = normals*grad_test.

Also, in MOOSE, any time a DG kernel is used for transport, a corresponding CG kernel must be used because the CG kernel actually computes the necessary element integrals (e.g. it adds the residual contribution of the element volume integrals.) DG appears to converge with both monomials and lagrange functions.

Penalty terms are essentially artificial dissipative terms. Reference: http://scicomp.stackexchange.com/questions/10928/in-what-regime-do-the-continuous-and-discontinuous-galerkin-method-become-unstab. 

DG does not require that the solution be continuous at nodes, but rather introduces a jump penalty term that adds an amount to the residual proportional to the solution jump discontinuity. CG is a limit of DG for some particular case of epsilon and sigma (I can't recall what the settings are. I know it's just taking one of the parameters to infinity, sigma I believe).

DG does not require solution continuity, however, the solution can be continuous. Thus Lagrange shape functions can be used. CG requires continuity, so Lagrange shape functions are desirable because they are continuous at the nodes.  

The idea of using argon excitation to bring down the electron density is a bust. It does bring down the electron density...but way too much. This makes sense because for all energies in the domain, the excitation coefficient is larger than the ionization coefficient. Thus excitation processes will occur at a greater rate, bringing down the electron energy such that there is never appreciable ionization. This is not a problem in LFA where an excitation event wouldn't destroy the quantity that ionization depends on. 

This morning's analysis validates Bolos IMHO. Now can proceed with introducing mean_energy dependent transport and rate parameters.

Hagelaar's paper is truly an excellent paper. I lot of excellent mathematical physics content. In our Boltzmann solver, the electron energy distribution is a function of E/N which is a function of E. E varies over our domain, thus our EEDF varies over the domain. D(EEDF(E(z))) -> thus in equation 54 of Hagelaar (the drift-diffusion coefficient), the diffusion coefficient shouldn't be extracted from the partial derivative. But to make my technical job easier, I might do just that. By doing this I'm essentially straying from the true physics. My residuals represent my physics. 

In my GeneralUserObject, when I try and compile it, I get these errors: 

/home/lindsayad/projects/zapdos/src/userobjects/ResidAndJacobTerms.C:27:22: error: 'coupledValue' was not declared in this scope
   _u(coupledValue("u")),
                      ^
/home/lindsayad/projects/zapdos/src/userobjects/ResidAndJacobTerms.C:28:30: error: 'coupledGradient' was not declared in this scope
   _grad_u(coupledGradient("u"))

I do not apparently have access to the functions coupledValue and coupledGraident. However, ElementIntegralVariableUserObject, obviously has access to it. How and why does it have access?

Where is the coupledValue function defined? It's defined in Coupleable.C. Thus I think that ElementIntegralVariableUserObject must somehow be a child of Coupleable. Looking at the inheritance diagram, this is exactly what we see:

Coupleable <- ElementUserObject <- ElementIntegralUserObject <- ElementIntegralVariableUserObject.

BlockAverageValue inherits from ElementIntegralVariablePostprocessor. ElementIntegralVariablePostprocessor -> ElementIntegralPostprocessor -> ElementPostprocessor -> ElementUserObject & Postprocessor

computeIntegral is defined in ElementIntegralPostprocessor:

  Real sum = 0;
   60 
   61   for (_qp=0; _qp<_qrule->n_points(); _qp++)
   62     sum += _JxW[_qp]*_coord[_qp]*computeQpIntegral();
   63   return sum;

computeQpIntegral() is defined in ElementIntegralVariablePostprocessor:

38  return _u[_qp];

Combining, computeIntegral executes: 

  Real sum = 0;
    
      for (_qp=0; _qp<_qrule->n_points(); _qp++)
        sum += _JxW[_qp]*_coord[_qp]*_u[_qp];
      return sum;

Children can override parent functions. 

gatherSum() is a function defined in UserObject.C and looks like this:

  _communicator.sum(value);

In the header file for libmesh::ParallelObject, there are three different options for constructing an object of type ParallelObject because there are three different constructors. That's all I'm going to write down for now. Have to walk a fine line between learning important c++ knowledge and not falling down a rabbit hole away from what I need to be focusing on. 

I want to be able to access _phi and _grad_phi. I need _assembly and _fe_type (this comes from looking at NodalNormalsPreprocessor).

_assembly is in UserObject -> Covered
_fe_type: first defined in Nodal... so I have to figure out how Nodal... got it

  /// Transformed Jacobian weights
  const MooseArray<Real> & _JxW;
  const MooseArray<Real> & _coord;

Active time for Zapdos with reduced ion diffusivity, variable electron energy coeff, and variable ionization coeff = 1911.58 seconds = 32 minutes. 
